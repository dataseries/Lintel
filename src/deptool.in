#!@PERL_PATH@ -w
# vim: set filetype=perl: # -*- Perl -*-
#
#  (c) Copyright 2004-2008, Hewlett-Packard Development Company, LP
#
#  See the file named COPYING for license details
=pod

=head1 NAME

deptool - a program for helping with the software development process

=cut

use strict;

use Carp;
use Cwd;
use Data::Dumper;
use English;
use Fcntl;
use File::Basename;
use File::Compare;
use File::Copy;
use File::Path;
use File::Find;
use File::stat;
use FileHandle;
use Getopt::Long;
use MIME::Base64;
use POSIX 'ceil';
use Pod::Usage;
use Safe;
use Sys::Hostname;
use Time::HiRes 'time';

BEGIN {
    # RHEL5 doesn't have Digest::SHA1 by default, only MD5
    eval "use Digest::SHA1 'sha1_hex';";
    if ($@) {
	die $@ unless $@ =~ m!Can.t locate Digest/SHA1.pm in !;
	eval "use Digest::MD5 'md5_hex';";
	die "Can not use Digest::SHA1 or Digest::MD5: $@" if $@;
	eval 'sub hexDigest { return md5_hex($_[0]); };';
	warn "Using Digest::MD5 instead of Digest::SHA1.
Install package or set the DEPTOOL_NOWARN_MD5 environment variable"
	    unless defined $ENV{DEPTOOL_NOWARN_MD5};
    } else{
	eval 'sub hexDigest { return sha1_hex($_[0]); };';
    }
    die $@ if $@;
}

@PERL5_MODULES_INC_UNSHIFT@
use Lintel::File::Lock;
use Lintel::ProcessManager;

# TODO: pull should walk in the current directory before walking in the
# dependent ones since it may need additional dependencies, and/or they
# may have changed.  Test case is revision in tla that switched the
# dependencies around.

# TODO: check for make file left overs in source directory (these should only
# be in build, or debug, or etc. directories). Jay at least seems to futz up
# and make crap in src every so often those breaking depbuild (or at least
# misleading it as to what has been created and what should be recreated).

# TODO: think about how to check for rebuild after make clean

# TODO: add ability to have hooks for pre-commit checks, this allows
# for mechanical verification of common errors.

# TODO: figure out a way to run all of the deptool commands for
# regression testing; this may need to wait until we have alternative
# monotone directory support.

# TODO: deptool should add text to the checkin message indicating 
# whether testing was performed for each commit.

sub usage {
    pod2usage(-exitval => 'NOEXIT', -verbose => 0);
    confess @_ if @_ > 0;
    exit(0);
}

=pod

=head1 SYNOPSIS

 % deptool <command> [--man] [options] [args]
   init [--server=<hostname>] [branch-prefix...]
   checkout <branch-substring...> # checkout branch and dependencies
   pull # pull branch and dependencies
   build [-t (and test)] [-d (debug build)] [-o (optimize build)] [-l|local]
   commit [--no-tests] # commit branch after dependencies
   publish # publish branch and dependencies
   cmake # run cmake with special options for current branch
   pin <revision> # pin branch at a particular revision
   code-review <revision...> # code-review a revision
   help [commands|options|environment|command-name] # get help

=head1 OVERVIEW

The deptool command is designed to assist with the software
development process.  In particular, it has support for getting the
version controlled copy of software via the monotone version control
system, building, committing, and publishing said software after
running appropriate tests, and easing code reviews of a collection of
changes.  Since software often has multiple dependencies that all need
to be built and updated, deptool is able to handle a related set of
software via version control dependencies specified as part of the
source code.  Since you may want to build software with multiple
options, deptool is able to handle additional build-type directories
which will automatically enable configuration with additional
arguments.  Deptool keeps stamp files so that it can avoid rebuilding
and testing a package which has dependencies from two separate places.

In general, use of deptool consists of the following steps:

    % deptool init # initial environment preparation
    % deptool checkout branch-substring... # checkout sources
    % cd ~/projects/project-name
    % deptool build # build project-name and its dependencies
    # edit the source code
    % deptool commit # optional; if it's not yet ready to be public
    % deptool publish # make changes visible to other people

To set up the environment, and make it easier to move between the
source and build directories, you probably want to put something like
the following in your shell startup files; unfortunately the cdopt and
cddebug bits only work under sh-based shells right now.

    DEPTOOL=`(echo $HOME/build/opt*/bin/deptool) 2>/dev/null | awk '{print $1}'`
    eval `$DEPTOOL getenv for-sh`

    s () { eval `$DEPTOOL cdsrc $PWD` }
    b () { eval `$DEPTOOL cdopt $PWD "$@"` }
    d () { eval `$DEPTOOL cddebug $PWD "$@"` }
    # note in bash you have to put returns after the { and before the }

Occasionally if something has been incorrectly committed, or you want
to force reconfiguration, you may need commands like:

    % deptool pin <revision> # work around bad published revision
    % deptool cmake clean # clean out cmake config files
    % deptool cmake # rebuild the cmake configuration
    % make -j $MAKE_PARALLELISM # rebuild in parallel using the deptool env

To use deptool, you need to have at least a minimal deptool.config file 'C<{
}>'.  This file is described in detail in the deptool.config section.  A more
normal configuration file would list the dependencies and enable parallel
testing.  Such a configuration might look like the following:

    {
	dependencies => [qw/Lintel OtherPackage/],
	parallel_test => 1,
    }

=cut

my $auto_yes_to_prompts = 1;
my $quiet = 0;
my $print_manpage = 0;
my $noconfig = 0;
my $time_log;
my $debug = 0;
my $monotone_dir = $ENV{MONOTONE_DIR};
$monotone_dir ||= "$ENV{HOME}/.monotone";

$Global::last_stamp_timestamp = time();

my @original_arguments = @ARGV;
Getopt::Long::Configure(qw/pass_through no_auto_abbrev/);
GetOptions("auto-yes!" => \$auto_yes_to_prompts,
           "quiet!" => \$quiet, 
	   "noconfig!" => \$noconfig,
           "projects=s" => \$Cache::projects,
           "build-root=s" => \$Cache::build_root,
           "operating-system=s" => \$Cache::operating_system,
           "uname-m=s" => \$Cache::uname_m,
           "build-debug=s" => \$Cache::build_debug,
           "build-opt=s" => \$Cache::build_optimize,
	   "man!" => \$print_manpage,
	   "monotone-dir=s" => \$monotone_dir,
	   "time-log=s" => \$time_log,
	   "debug!" => \$debug);

$time_log ||= $ENV{DEPTOOL_TIME_LOG};
if (!defined $time_log) {
    my $default_time_log = "$monotone_dir/deptool-timings";
    $time_log = $default_time_log if (-f $default_time_log);
}

=pod

=head1 OPTIONS

=over 4

=item --no-auto-yes 

Do not automatically answer 'yes' to all of the prompts that are
provided if there is a sane default answer.  Default is true because
in practice that's what everyone did.

=item --quiet

Print out less output by default; the output from the commands being
run will still be printed out.

=item --projects=<path>

Specify the default projects directory.  Normally this would come from
the PROJECTS environment variable, which defaults to ~/projects.

=item --build-root=<path>

Specify the default root build directory.  Normally this would come from
the BUILD_ROOT environment variable, which defaults to ~/build.

=item --operating-system=<string>

Specify the operating system's name.  Normally this would be specified
in the OS environment variable, which defaults to various strings depending
on the inferred operating system, e.g. debian-etch, or rhel5.

=item --uname-m=<string>

Specify the hardware machine type.  Normally this would be specified
by the UNAME_M environment variable, which defaults to the output from
uname -m.

=item --build-debug=<path>

Specify the debugging build directory.  Normally this would be
specified by the BUILD_DEBUG environment variable, which defaults to
$BUILD_ROOT/dbg-$OS-$UNAME_M, or $BUILD_ROOT/debug if that directory
exists.

=item --build-opt=<path>

Specify the optimize build directory.  Normally this would be
specified by the BUILD_OPT environment variable, which defaults to
$BUILD_ROOT/opt-$OS-$UNAME_M, or $BUILD_ROOT/optimize if that
directory exists.

=item --monotone-dir=<path>

Specify the directory to search for monotone databases that include
the current project.  This can be also be specified using the 
MONOTONE_DIR environment variable, or failing that, the directory
defaults to $HOME/.monotone.

=item --time-log=<path>

Specify the file to use for logging build times.  The default is
I<monotone-dir>/deptool-timings.  If the file is present then deptool
will write a base64 encoded log entry for each command. Unsuccessful
commands or commands that are aborted with a ^C are not logged.  The
default file can be specified using the DEPTOOL_TIME_LOG environment
variable.

=item --man

Print out the complete manual page.

=back

=cut

Getopt::Long::Configure(qw/no_pass_through auto_abbrev/);

help("all") if $print_manpage;

usage("Missing argument") if @ARGV == 0;

my %commands = ('checkout' => \&depCheckout,
		'co' => \&depCheckout,
                'pull' => \&depPull,
                'build' => \&depBuild,
#		'clear' => \&depClear,
                'commit' => \&depCommit,
                'publish' => \&depPublish,
                # below commands don't run in all dep dirs.
                'init' => \&depInit,
		'tarinit' => \&depTarInit,
                'cmake' => \&runCMake,
                'pin' => \&setPin,
                'code-review' => \&codeReview,
                'mtnpull' => sub { mtnOp("pull"); },
                'mtnpush' => sub { mtnOp("push"); },
                'mtnsync' => sub { mtnOp("sync"); },
                'mtnserve' => \&mtnServe, 
                'getenv' => \&getEnv,
                'cdsrc' => \&cdSrc,
                'cdopt' => sub { cdBuild('opt'); },
                'cddebug' => sub { cdBuild('debug'); },
		# get usage without error message
		'-h' => \&usage,
		'--help' => \&usage,
		'help' => sub { help(@ARGV); },
);

=pod

=head1 COMMANDS

Further details on all commands can be found by running C<deptool
help> I<command>

=over 4

=item init [I<--server=hostname>] [I<branch-prefix>]

Initialize the system, this will create the appropriate version
control files, and will pull the initial database(s).

=item tarinit [I</path/to/tar.bz2>...] [I<http://host/path/to/tar>] 
      [I<http://host/path/to/latest-release]

Initialize the system.  This will optionally download and unpack the
specified source packages.

=item checkout I<branch-substring>

Select a particular branch by using branch-substring.  Checkout that
branch and all of its dependencies into $PROJECTS.  You can use co as
a shorter alias for this command.

=item pull 

Select the current branch based on the current directory.  Pull the
current branch and all it's dependencies from the server specified in
the _MTN directory.

=item build [I<-t>] [I<-d>] [I<-o>]

Build and install the current branch after building and installing its
dependencies.  Select the type of build (debug or optimized) based on
the current directory or the options.  

=item commit [I<--no-tests>] [I<-d>] [I<-o>]

Commit the current branch after committing its dependencies.  If there
are unknown files, prompt for them to be either added or ignored.  If
there are changes, perform a build before performing the commit.

Tests will be run by default before committing, but can be disabled
with --no-tests.  You can also specify the build type to be run before
committing.

=item publish

Perform the full publishing steps; first run a commit, then build and
test, next pull and update.  If no changes were made, synchronize the
updates to the central server.  Alternately, restart the loop at the
build and test stage.

=item cmake [I<--clean> | I<clean>]

Run the cmake configuration command, or clean out the cmake
configuration files.  See help cmake for details on how cmake is
run.

=item pin I<revision>

Pin the current source directory to a particular revision after
updating the current source directory to that revision.

=item code-review I<revision>...

Perform a code review of the selected revisions.  This will treat the
collection of revisions as if they were a single change.  Currently it
works poorly if there are renames in the changes.

=item mtnpull

Run the mtn pull operation with the appropriate options based on the
current directory.

=item mtnpush

Run the mtn push operation with the appropriate options based on the
current directory.

=item mtnsync

Run the mtn sync operation with the appropriate options based on the
current directory.

=item mtnserve

Start up a monotone server based on the database for the current
directory.

=item getenv I<variable> I<for-{sh,csh}>

Print the selected environment information.  If a variable is
specified, then just that variable will be printed.  If for-sh or
for-csh is specified, then all environment variables will be printed
using the syntax of the specified shell.

=item cdsrc I<dir>

Print out the command to cd to the source directory for the specified
directory.

=item cdopt I<dir> [I<build-type>]

Print out the command to cd to the optimized build directory for the
specified directory and optional build type.  Currently does not work
for csh-style shells.

=item cddebug I<dir> [I<build-type>]

Same as cdopt, except for the debug build directory.

=back

=head1 COMMAND DETAILS

=cut

{
    my $command = shift @ARGV;
    my $fn = $commands{$command};

    usage("Unrecognized command '$command'") unless defined $fn;
    $|=1;
    
    # handle case where start dir is a symlink
    aliasChdir($ENV{PWD}) if defined $ENV{PWD};
    my $start_time = time;
    &$fn;
    addTimeLog($start_time);
}

sub addTimeLog {
    my ($start_time) = @_;

    return unless defined $time_log;

    my $timelog_entry = {
	    version => 1,
	    command => [$0, @original_arguments ],
	    host => hostname,
	    directory => getcwd,
	    starttime => $start_time,
	    endtime => time
	};
	
    if (my $lock = Lintel::File::Lock::getLockEx($time_log, waittime => 5, 
						 flags => O_WRONLY | O_CREAT | O_APPEND)) {
	my $doc = encode_base64(Dumper($timelog_entry), '');
	my $sha1 = hexDigest($doc);
	print $lock "$doc $sha1\n" or die "print failed: $!";
	close $lock or die "close failed: $!";
    } else {
	warn "Skipping time logging; unable to lock $time_log\n";
    }

    # TODO: add code that parses the time logs and writes out SQL for mercury.
}

# TODO: factor this out into a library so that it can be used by lots
# of things.
sub helpSection {
    my ($section) = @_;

    my $fn;

    if ($PERL_VERSION ge v5.10) {
	eval q! # checked on Debian Lenny, openSUSE 11.1
	    use IO::String;
            use Pod::Select;
	    use Pod::Text::Termcap;

	    my $out = IO::String->new;

	    podselect({-sections => [$section], -output => $out }, $0);

	    my $to_text = new Pod::Text::Termcap;
	    $out->setpos(0);
	    $to_text->parse_from_filehandle($out);
	!;
	if ($@ && $@ =~ m!Can.t locate IO/String.pm in!o) {
	    # Write out to a temporary file.
	    eval q!
                use Pod::Select;
                use File::Temp;
	        use Pod::Text::Termcap;

                my $fh = new File::Temp();
                # Couldn't figure out how to pass just the handle to podselect;
                # the idiom suggested on the File::Temp page didn't work (wrote
                # to the redirect as if it was a filename)
	        podselect({-sections => [$section], -output => $fh->filename }, $0);
	        my $to_text = new Pod::Text::Termcap;
	        $to_text->parse_from_file($fh->filename);
            !;
        }

    } else {
	# RHEL4 (perl 5.8.5), Debian Etch (perl 5.8.8)
	# -sections => ... works on Etch but not RHEL4
	$fn = eval q!
	    my $parser = new Pod::Usage(USAGE_OPTIONS => {-verbose => 99});

	    $parser->select($section);
	    $parser->parse_from_file($0);
        !;
    }

    die "Eval-for-docs failed: $@" if $@;

    exit(0);
}

sub help {
    my ($what) = @_;
    $what ||= 'all';
    if ($what eq 'all') {
	# Might be able to get rid of the 'user contributed perl doc'
	# stuff in the man page title by invoking perldoc ourselves.
	pod2usage(-verbose => 2, -exitval => 0);
    } elsif ($what eq 'commands') {
	helpSection("COMMANDS");
    } elsif (defined $commands{$what}) {
	helpSection("COMMAND DETAILS/^$what(\\s.*)?\$");
    } else {
	usage("Unknown option to help '$what'");
    }

    exit(0);
}

##### Pre-declarations

sub depWalk ($$$);

##### Dependency Init

=pod

=head2 init [--server=<hostname>] [I<branch-prefix>...]

The init command will initialize the default setup for the monotone version
control system.  It will also populate the initial database for checkouts, in
particular, the one that would contain Lintel since deptool is in Lintel.  By
default it assumes that usi.hpl.hp.com is the central version control server,
but this can be overridden with the --server option.  It will use ssd as the default
branch prefix.  If you do not have the environment variables set up by using
the getenv command, deptool will ask a number of questions about where the
files should be placed.  It is usually safe to run the init command with the -y
option so that these questions will be automatically answered.

After you have run init, you will have a key file.  To be able to sync to a
particular server, you need to send the public key to the monotone
administrator for that server.  You can get the key file by running mtn pubkey
I<email-address>, the same address you used when running deptool init.  For
HP Labs, the administrator of usi.hpl.hp.com is anderse@hpl.hp.com.

B<Warning:> If you already have a key set up on one machine, you should just
copy your keys directory to the new machine rather than creating a new key.
Monotone can get confused by multiple keys with the same email address.

=cut

sub depInit {
    checkForMtn();

    my $server = mtnServer();
    my $email;
    my $result = GetOptions("server=s" => \$server);
    usage("Unknown error") unless $result;
    my @branch_prefixes = @ARGV;
    if (@branch_prefixes == 0) {
        print "Assuming default branch prefix ssd\n";
        @branch_prefixes = ("ssd");
    }

    initMtnDir();
    initMtnKeysRc();

    initDbs($server, \@branch_prefixes);
}

sub checkForMtn {
    my @paths = split(/:/, $ENV{PATH});
    foreach my $path (@paths) {
        return if -x "$path/mtn";
    }
    die "Unable to find mtn binary in path; you should repair this.
Usually yum install monotone or apt-get install monotone will work.
http://usi.hpl.hp.com/twiki/pub/USI/MonotoneVersionControl/mtn-static
is a static linux binary, alternately, you can get something from
the monotone web site: http://www.monotone.ca/";
}

sub initMtnDir {
    if (! -d $monotone_dir) {
        userPrompt("Create monotone directory $monotone_dir");
        mkdir($monotone_dir, 0755) or die "Unable to mkdir $monotone_dir: $!";
    }
}

sub initMtnKeysRc {
    if (! -d "$monotone_dir/keys") {
        print <<EOF;

The key will be generated with an empty password.  You can change it
by running mtn chkeypass or mtn passphrase depending on your monotone
version. 

Run 'deptool help publish' to learn where you have to send your public key
so tha tyou can publish.

WARNING: if you already have a monotone key, you should ctrl-c now, and copy
WARNING: your key file over.  Monotone deals poorly with multiple keys with
WARNING: the same e-mail address.
EOF

        print "Enter e-mail address for identifying monotone key: ";
        my $email = <STDIN>;
        chomp $email;
        die "?? $email" unless $email =~ /^\S+\@\S+\.\w+$/o;

        runCommand("yes default-password | mtn genkey $email");

        print <<"END";
Key generated with password 'default-password'; can be changed with
mtn chkeypass or mtn passphrase depending on your monotone version
END

        chmod(0700, "$monotone_dir/keys");
        if (-f "$monotone_dir/monotonerc") {
            print <<"EOF";
You probably want to add:
function get_passphrase(keypair_id)
  return "default-password"
end
To your $monotone_dir/monotonerc file
EOF
        } else {
            userPrompt("Create default monotonerc?");
            my $mtnrc = new FileHandle(">$monotone_dir/monotonerc")
                or die "can't write $monotone_dir/monotonerc: $!";
            print $mtnrc <<"EOF";
-- Change with mtn chkeypass or mtn passphrase, then change here.
function get_passphrase(keypair_id)
  return "default-password"
end

-- Next three are for letting you run your own server 
function get_netsync_read_permitted (collection, identity)
  return true
end

function get_netsync_write_permitted (identity)
  if (identity == "$email") then return true end
  return false
end

function get_netsync_anonymous_read_permitted (collection)
  return true
end

-- performance optimization
function get_vcache_size()
  return 512*1024*1024
end
EOF
            chmod(0700, "$monotone_dir/monotonerc");
        }
    }
}

sub initDbs {
    my($server, $branch_prefixes) = @_;

    foreach my $branch_prefix (@$branch_prefixes) {
        my $db = $branch_prefix;
        $db =~ s/\W.*$//o;
        die "Invalid branch prefix $branch_prefix, should start with normal chars"
            if $db eq '';
        unless (-f "$monotone_dir/${db}.db") {
            userPrompt("create local repository $monotone_dir/${db}.db");
            runCommand("mtn -d $monotone_dir/${db}.db db init");
        }

        userPrompt("pull $branch_prefix* from $server (can take a while)");
        my $qm = quotemeta $branch_prefix;
        runCommand("mtn -d $monotone_dir/${db}.db pull $server $qm\\*");
    }
}

=pod

=head2 tarinit [--no-cache] [I<download-specification>]

The tarinit command will initialize the software packages based on tar files.
It has three possible types of download specifications, listed below.  If no
arguments are specified, then it defaults to
http://tesla.hpl.hp.com/opensource/latest-release; which will download the
open-source packages available on tesla and unpack then.  If the --no-cache
option is specified, tarinit will provide --no-cache as an option to wget.

=over 4

=item I</path/to/file.tar.bz2>

This specifies that deptool should unpack the specified tar file into the
projects directory.  The tar file will normally unpack into a directory names
I<package>-I<date>, in which case the -I<date> portion will be removed.  If
there is already a I<package> available in the projects directory, it will only
be replaced if it has a different release date than the file.tar.bz2 one.

=item I<http://host/path/to/tar>

This specifies that deptool should first download the tar file into the
projects directory and then unpack it as if the downloaded file had been
specified to tarinit.  Deptool will use wget to download the file.  If the tar
file has already been downloaded, it will just be used.

=item I<http://host/path/to/latest-release>

This specifies that deptool should download the specified text file, and should
then download all of the packages specified in the latest-release file.

=back

=cut

sub depTarInit {
    my $no_cache = 0;

    my $result = GetOptions("no-cache!" => \$no_cache);

    usage("Unknown error") unless $result;

    my (@files) = @ARGV;

    @files = "http://tesla.hpl.hp.com/opensource/latest-release"
	if @files == 0;
    my $startdir = aliasGetCwd();

    mkpath(projects());
    aliasChdir(projects());

    my $cache = $no_cache ? "--no-cache" : "";
    foreach my $file (@files) {
	if (-f $file && -r $file) {
	    unpackProjectsTar($file);
	} elsif (-f "$startdir/$file" && -r "$startdir/$file") {
	    unpackProjectsTar("$startdir/$file");
	} elsif ($file =~ m!^http:.*latest-release!o) {
	    httpFetchLatestRelease($file, $cache);
	} elsif ($file =~ m!^http:!o) {
	    httpFetchUnpackTar($file, $cache);
	} else {
	    die "Unrecognized argument '$file', expected either /path/to/tar or http://url";
	}
    }
}

sub maybeBackupOldProjectDir {
    my ($project, $date, $source) = @_;

    my $projects = projects();

    if (-e "$projects/$project") {
	if (! -r "$projects/$project/Release.info") {
	    backupUntarDir("$projects/$project", "Missing Release.info file");
	} else {
	    my $fh = new FileHandle "$projects/$project/Release.info"
		or die "Can't open $projects/$project/Release.info for read: $!";
	    my $creation_date;
	    while (<$fh>) {
		$creation_date = $1 if /^Creation-Date: (\S+)$/o;
	    }
	    close($fh);

	    if (! defined $creation_date) {
		backupUntarDir("$projects/$project", "No creation date in Release.info file");
	    } elsif ($creation_date ne $date) {
		backupUntarDir("$projects/$project", 
			       "Creation date in Release.info file different from one in tar file");
	    } else {
		print "$projects/$project is already the same as in $source\n";
		return 1;
	    }
	}
    }
    die "$projects/$project exists?"
	if -e "$projects/$project";
    return 0;
}

sub unpackProjectsTar {
    my ($file) = @_;

    die "Expected $file to end in .bz2"
	unless $file =~ /\.bz2$/o;

    my $fh = new FileHandle "tar tvvfj $file |"
	or die "Can't run tar tvvfj $file: $!";
    local $_ = <$fh>;
    close($fh);
    chomp;
    die "Unable to handle '$_'" 
	unless m!^d.+ (\w+)-(\d{4}-\d{2}-\d{2})/!o;
    my ($project, $date) = ($1,$2);

    return if maybeBackupOldProjectDir($project, $date, $file);

    my $projects = projects();
    if (-d "$project-$date") {
	userPrompt("Delete $projects/$project-$date");
	rmtree("$project-$date");
    }

    userPrompt("Untar $file into $projects");
    system("tar xvvfj $file");
    die "Did not get expected directory $project-$date"
	unless -d "$project-$date";
    rename("$project-$date","$project")
	or die "Unable to rename $project-$date to $project";
}

sub backupUntarDir {
    my ($dir, $reason) = @_;

    print "Backing up $dir.\n$reason\n";
    if (-d "$dir.old") {
	userPrompt("Delete old backup directory $dir.old");
	rmtree("$dir.old");
    }
    userPrompt("Rename $dir to $dir.old");

    rename($dir, "$dir.old")
	or die "rename($dir, $dir.old) failed: $!";
}

sub httpFetchUnpackTar {
    my ($url, $no_cache) = @_;

    die "Bad url '$url', expected http://.*/\\w+-\\d{4}-\\d{2}-\\d{2}.bz2"
	unless $url =~ m!^http://.*/(\w+)-(\d{4}-\d{2}-\d{2}).tar.bz2$!o;
    my ($project, $date) = ($1, $2);

    return if maybeBackupOldProjectDir($project, $date, $url);

    my $output = "$project-$date.tar.bz2";
    if ($no_cache ne '') {
	unlink($output);
	die "Unable to rm $output: $!" if -e $output;
	rmtree("$project-$date") if -d "$project-$date";
    }

    if (! -e $output) {
	userPrompt("wget $no_cache $url");
	my $ret = system("wget -O $output.tmp $url");

	die "wget $url failed" unless $ret == 0 && -r "$output.tmp";
	rename("$output.tmp", $output)
	    or die "Unable to rename $output.tmp to $output: $!";
    }
    unpackProjectsTar(projects() . "/$output");
}

sub httpFetchLatestRelease {
    my ($url, $no_cache) = @_;

    userPrompt("download $url");
    print "Downloading $url using http proxy '$ENV{http_proxy}'\n"
	if $debug;
    my $fh = new FileHandle("wget $no_cache -O - $url |")
	or die "Can't run wget $no_cache -O - $url: $!";
    my @suburls = <$fh>;
    close($fh);

    foreach my $suburl (@suburls) {
	my $tmp = $url;
	$tmp =~ s/latest-release$/$suburl/o;
	httpFetchUnpackTar($tmp, $no_cache);
    }
}

##### Dependency Checkout

=pod

=head2 checkout I<branch-substring>...

The checkout command, which can be abbreviated as co, checks out a
branch and its dependencies.  It will find the appropriate branch by
selecting from all the branches in the databases found as
~/.monotone/*.db.  It will choose the directory name based on the
branch name after stripping out the initial uniquifier.  This is based
on the assumption that branches will be named as
I<uniquifier>/I<branch-name>/I<sub-branch>.  Deptool will
automatically select the branch that matches with the least length so
it will ignore sub-branches that may be present.  For example, if you
ran checkout Data, it would select the ssd.hpl.hp.com/DataSeries
branch and put the checkout in ~/projects/DataSeries (by default,
changeable by setting $PROJECTS).  It would then checkout Lintel since
Lintel is a dependency for DataSeries.

If multiple branches match and they do not share a common prefix,
deptool will abort the checkout.

=head2 co

See help checkout

=cut

sub depCheckout {
    usage("No branch-substrings specified") unless @ARGV > 0;

    my $projects = projects();
    
    my @dbs = glob("$monotone_dir/*.db");
    die "No *.db files in $monotone_dir; did you run $0 init?"
        unless @dbs > 0;

    my @branches;
    my %branch_to_db;
    foreach my $db (@dbs) {
        my $tmp = new FileHandle("mtn -d $db list branches |");
        my @tmp = <$tmp>;
        close($tmp);
        grep(chomp, @tmp);
        push(@branches, @tmp);
        map { 
            warn "duplicate db ($db, $branch_to_db{$_}) for branch $_
will use latter."
                if defined $branch_to_db{$_};
            $branch_to_db{$_} = $db 
            } @tmp;
    }

    my @branch_regexes = (@ARGV);
    my %did_regex;
    while (@branch_regexes > 0) {
        my $branch_regex = shift @branch_regexes;
        next if $did_regex{$branch_regex};
        $did_regex{$branch_regex} = 1;

	$branch_regex =~ s/;\w+//o;
	$branch_regex = "/$branch_regex" unless $branch_regex =~ m!/!o;
        my @possibles = grep(m/$branch_regex/, @branches);
        die "No branches found matching $branch_regex"
            unless @possibles > 0;
        @possibles = sort { length $a <=> length $b } @possibles;
        
        my $branch = shift @possibles;
        foreach $_ (@possibles) {
            die "multiple non-prefixed matches for $branch_regex:
$branch $_
You need to provide more specificity in the dependencies in deptool.config\n " 
		unless /^$branch/;
        }
        
        my $db = $branch_to_db{$branch};
        my $dir = $branch;
        $dir =~ s!^\w+(\.\w+)*/!!o; # strip uniqueifier we put on
        my $path = "$projects/$dir";
        print << "END";

Selected branch $branch
From database $db
Inferred projects directory $dir
Inferred full path $path
END

        if (-d "$path/_MTN") {
            print "Found $path/_MTN; skipping redundant checkout.\n";
        } else {
	    die "$path already exists; mtn checkout would fail"
		if -d $path;
            userPrompt("continue even though you have a / in the directory")
                if $dir =~ m!/!o;
        
            runCommand("mtn -d $db co -b $branch $path");
        }
	my $config = readConfig($path);
        if (defined $config->{dependencies} && @{$config->{dependencies}} > 0) {
            print "Adding VC dependencies: ", join(" ", @{$config->{dependencies}}), "\n";
            push(@branch_regexes, @{$config->{dependencies}});
        }
    }        
}

##### Dependency build

=pod

=head2 build [I<-t>] [I<-d>] [I<-o>] [I<-l|--local>]

This command will build the current project directory after building and
installing all of the dependencies.  The type of build is determined by the
current directory and the options.  If either -d or -o are specified, then we
perform a debug or an optimized build respectively.  If we are in the projects
directory or an optimized build directory, we perform an optimized build.  If
we are in a debug build directory, we perform a debug build.  If -t is
specified, tests will be run in addition to building and installing each of the
packages.  If -l is specified, only the build for the local directory will be
performed, none of the dependencies will be rebuilt.

If a directory hasn't been configured, then the deptool cmake command
will be automatically run to configure the package before it is built.

=cut

sub depBuild {
    my %options = (tests => 0, local_only => 0);

    my $cwd = aliasGetCwd();
    my $debug = buildDebug();
    if ($cwd =~ /^$debug/o) {
        $options{mode} = 'debug';
    } else {
        $options{mode} = 'optimize';
    }

    my $ret = GetOptions("t|tests!" => \$options{tests},
                         "o|optimize" => sub { $options{mode} = 'optimize' },
                         "d|debug" => sub { $options{mode} = 'debug' },
			 "l|local!" => \$options{local_only});
			 
    usage("unknown option to build") unless $ret;

    $options{builddir} = $options{mode} eq 'debug' ? buildDebug() : buildOpt();
    $options{projects} = projects();

    return depBuildParallel(\%options);
}

sub parseDependency { 
    my ($dep) = @_;
    my $sub_build_type;
    $dep =~ s!^[^/]*/!!;
    if ($dep =~ /^(.+);(\w+)$/o) {
	($dep,$sub_build_type) = ($1,$2);
    }
    $sub_build_type ||= '';
    return ($dep, $sub_build_type);
}

sub dbpFindOld {
    my ($src) = @_; 
    confess "?? $src" unless defined $src && -d $src && -f ".deptool.build_stamp";

    my $ref_stat = stat(".deptool.build_stamp")
        or die "Unable to stat .deptool.build_stamp: $!";
    my @newer;
    find(sub { return unless -f $_;
               return if $File::Find::name =~ m!^$src/_MTN!;
               my $stat = stat($_) or die "can't stat $_: $!";
               push(@newer, $File::Find::name)
                   if $stat->mtime() > $ref_stat->mtime(); }, $src);
               
    return @newer;
}

sub dbpBuildMake {
    my($src, $build) = @_;

    if (-f ".deptool.build_stamp") {
        print "depbuild: $build already has current build\n";
        return;
    }
    if (! -f "Makefile" || ! -d "CMakeFiles" || ! -f "CMakeCache.txt") {
        local @ARGV = ();
        print "depbuild: creating makefile in $build\n";
        runCMakeConfig();
    }

    print "depbuild: building...\n";
    my $make_parallelism = makeParallelism();
    runCommand("make", "-j", $make_parallelism);
    stamp("build");
}

sub stampUpToDate {
    my($which, $options) = @_;

    return 0 unless -f ".deptool.${which}_stamp";
    my $build_stat = stat(".deptool.build_stamp")
        or confess "Unable to stat .deptool.build_stamp: $!";
    my $which_stat = stat(".deptool.${which}_stamp")
        or die "Unable to stat .deptool.${which}_stamp: $!";
    if (defined $options && $which eq "install") {
        my $lastbuild = $options->{"lastbuild $options->{building}"};
        if (!defined $lastbuild || $lastbuild < $which_stat->mtime()) {
	    $options->{"lastbuild $options->{building}"} = $which_stat->mtime();
	}
    }
    return ($which_stat->mtime() > $build_stat->mtime());
}

sub stampTime {
    my ($build_path, $which) = @_;

    my $file = "$build_path/.deptool.${which}_stamp";
    return 0 unless -f $file;
    my $stat = stat($file) or die "Can't stat $file: $!";
    return $stat->mtime();
}

sub stamp {
    my($which, $options) = @_;
    
    my $filename = ".deptool.${which}_stamp";

    my $fh = new FileHandle("+>>$filename")
	or die "Can't open $filename for append: $!";
    close($fh);

    ++$Global::last_stamp_timestamp; # ensure uniqueness
    while (1) {
	my $now = time();
	utime undef, undef, $filename;
	my $st = stampTime(".", $which);

	if ($now < $st - 2 || $now > $st + 2) {
	    my $delta = $now - $st;
	    warn "Weird discrepancy in filesystem timestamp vs. machine timestamp.
Machine is at $now, Filesystem at $st, machine - fs = $delta";
	}

	if ($st >= $Global::last_stamp_timestamp) {
	    $Global::last_stamp_timestamp = $st;
	    last;
	}

        print "deptool: sleep(0.25) for unique .deptool.*_stamp file timestamps\n"
	    if 0;
	select(undef,undef,undef, 0.25);
    }
}

sub projectBuildPath {
    my ($build_dir, $project, $sub_type) = @_;

    confess "internal" unless defined $build_dir;
    my $dir = "$build_dir/$project";
    $dir .= "-$sub_type" if $sub_type ne '';
    return $dir;
}

sub dbpOutOfDate {
    my ($build_path, $dependencies, $info) = @_;

    my $build_stamp = stampTime($build_path, "build");
    my $out_of_date = $build_stamp > 0 ? 0 : 1;
    my $deps_done_all_installs = 1;

    map { 
	my $path = $_;
	my $dep_info = $dependencies->{$path};

	if ($dep_info->{src} eq $info->{src}) { 
	    # ignore self dependencies
	} else {
	    if ($dep_info->{done_install}) {
		my $them_install_stamp = stampTime($path, 'install');
		$out_of_date = 1 if $build_stamp <= $them_install_stamp;
	    } else {
		$deps_done_all_installs = 0;
	    }
        }
    } keys %{$info->{deps}};
    
    return ($build_stamp, $deps_done_all_installs, $out_of_date);
}

sub dbpStartBuild {
    my ($children, $pending, $dependencies) = @_;

    for (my $i=0; $i < @$pending; ++$i) {
	my ($build_path, $type) = @{$pending->[$i]};
	next unless $type eq 'build';

	unless (-d $build_path) {
	    mkpath($build_path) or die "Can not mkdir($build_path): $!";
	}
	aliasChdir($build_path);

	my $info = $dependencies->{$build_path};

	my ($build_stamp, $deps_done_all_installs, $out_of_date) 
	    = dbpOutOfDate($build_path, $dependencies, $info);

	next unless $deps_done_all_installs;

	splice(@$pending, $i, 1);

	aliasChdir($build_path);

	if (!$out_of_date && $build_stamp > 0) {
	    my @old = dbpFindOld(projects() . "/$info->{src}");
	    if (@old > 0) {
		print "Local rebuild of $build_path\n";
		$out_of_date = 1;
	    }
	}

	if ($out_of_date) {
	    print "Start build in $build_path\n";
	    unlink(".deptool.build_stamp");
	    $info->{running_build} = 1;

	    $children->fork(
		 cmd => sub {
		     # builds are nice to be behind install/test
		     POSIX::nice(10) or die "nice failed: $!";
		     dbpBuildMake($info->{src}, $build_path);
		 },
		 exitfn => sub { $info->{running_build} = 0; $info->{status_build} = $_[1]; },
		 stdout => 'deptool.build.out', stderr => 'deptool.build.err');

	    return $build_path;
	} else {
	    print "Up to date build in $build_path\n";
	    $info->{done_build} = 1;
	    return undef;
	}
    }
    # print "No builds active\n";
    return undef;
}

sub dbpGetCTestInfo {
    my $tests = new FileHandle "ctest -N |"
	or die "Can't run ctest -N";
    $_ = <$tests>; die "?" unless /^Start processing tests$/o;
    $_ = <$tests>; die "?" unless /^Test project \S+$/o;

    my $maxtest = 0;
    my @testlist;
    while(<$tests>) {
	die "?" unless m!^\s*\d+/\s*(\d+)\s* Testing (\S+)\s*$!o;
	push(@testlist, $2);
	$maxtest = $1;
    }
    close($tests);
    die "test count mismatch" unless @testlist == $maxtest;
    return @testlist;
}

sub dbpGetTestStatus {
    my ($num) = @_;

    my $file = "Testing/Parallel/$num/handler_output";
    my $fh = new FileHandle($file) or die "can't read $file: $!";
    $_ = <$fh>; die "?" unless /^Test project \S+$/o;
    $_ = <$fh>; die "?" unless /^$/o;
    $_ = <$fh>; die "?" unless m!^\s*(\d+)/$!o;
    my $tnum = $1;
    chomp;
    my $tnum_line = $_;
    die "internal $tnum $num" unless $tnum == $num;
    $_ = <$fh>; 
# TODO: handle file like:
#Test project /.home-bill-h/anderse/build/opt-debian-4.0-i686/KeyValue
#
#110/
#158 Testing fs-disk-converge-retrieve-fail***Exception: 
#SegFault
#
#0% tests passed, 1 tests failed out of 1
#
#        110 - fs-disk-converge-retrieve-fail (SEGFAULT)

    die "$file missing test status?" 
	unless m!^\s*\d+ Testing (.*?)\s+(\S+)\s*$!o;
    my ($test_name, $status) = ($1, $2, $3);
    return ("${tnum_line}$_", $test_name, $status);
}

sub dbpReadCTestOutput {
    my ($filename) = @_;

    my $fh = new FileHandle($filename) or die "Unable to open $filename for read: $!";
    my $cur_section = 'unknown';
    my $ret = {};
    while (<$fh>) {
	if (s/\[([A-Z_]+)\] \n$//o) {
	    my $new_section = $1;
	    $ret->{$cur_section} .= $_ if $_ ne '';
	    $cur_section = $new_section;
	} else {
	    $ret->{$cur_section} .= $_;
	}
    }
    die "did not find sections in $filename" if $cur_section eq 'unknown';
    
    return $ret;
}

sub dbpRunIndividualTest {
    my ($test) = @_;

    print "Start test at ", time, "\n";
    $ENV{DEPTOOL_PARALLEL_TEST_NUM} = $test;
    my $testdir = "Testing/Parallel/$test";
    my $time = "/usr/bin/time";
    $time = '' unless -x $time;
    my $fh = new FileHandle("$time ctest -V -O $testdir/log -I $test,$test,1 2>&1 |")
	or die "Can not fork ctest: $!";

    while(<$fh>) {
	# throw this all away, it's intermingled output streams
	# without any signals of separation, so is effectively
	# useless.
	if (/user.*system.*CPU/o) {
	    print $_;
	}
    }
    my $ok = close($fh) || 0; 
    print "End test at ", time, "\n";

    my $sections = dbpReadCTestOutput("$testdir/log");

    while (my ($section, $data) = each %$sections) {
	$section =~ tr/A-Z/a-z/;
	my $filename = "$testdir/$section";
	my $fh = new FileHandle(">$filename") or die "can not write $filename: $!";
	print $fh $data or die "can't print to $filename: $!";
	close($fh) or die "can't close $filename: $!";
    }

    if ($ok) {
	rename("$testdir/handler_verbose_output", "$testdir/success_output")
	    or die "rename failed: $!";
	die "Ok, but missing Passed in handler_output"
	    unless $sections->{HANDLER_OUTPUT} =~ /Passed/o;
	exit(0);
    } else {
	rename("$testdir/handler_verbose_output", "$testdir/failure_output")
	    or die "rename failed: $!";
	die "Not ok, but have Passed in handler_output"
	    if $sections->{HANDLER_OUTPUT} =~ /Passed/o;
	exit(3);
    }
}

sub dbpDoParallelTest {
    my ($build_path, $config) = @_;

    my @testlist = dbpGetCTestInfo();

    die "unimplemented no tests" unless @testlist > 0;

    my $children = new Lintel::ProcessManager(auto_kill_on_destroy => 1);
    my $parallelism = $ENV{MAKE_PARALLELISM} || 1;

    map { rmtree($_) if -d $_ } qw(Testing/Temporary Testing/Parallel);

    mkpath("Testing/Parallel");

    my @status = map { 77 } 1 .. scalar @testlist;

    my $starttest = sub {
	my ($test) = @_;

	my $testdir = "Testing/Parallel/$test";
	mkdir($testdir, 0777) or die "Can not mkdir $testdir: $!";

	$children->fork(cmd => sub { dbpRunIndividualTest($test); },
			exitfn => sub { $status[$test] = $_[1]; },
			stdout => "$testdir/deptool_out", stderr => 'STDOUT');
    };

    my %sequential_tests;
    if (defined $config->{sequential_tests}) {
	print "Running sequential tests.\n";
	foreach my $test (@{$config->{sequential_tests}}) {
	    my @match_nums;
	    for (my $testnum = 0; $testnum < @testlist; ++$testnum) {
		next unless $testlist[$testnum] =~ /$test/;
		push (@match_nums, $testnum + 1); # ctest counts from 1.
	    }
	    die "Did not find any test that matched $test"
		unless @match_nums > 0;
	    foreach my $match_num (@match_nums) {
		if ($sequential_tests{$match_num}) {
		    warn "Already ran test $match_num ($test)";
		    next;
		}
		$sequential_tests{$match_num} = 1;
		print "Test $match_num\n";
		&$starttest($match_num);
		$children->wait();
		die "?" unless $children->nChildren() == 0;
	    }
	}
    }

    print "Running parallel tests:\n";
    for (my $i = @testlist; $i >= 1; --$i) {
	next if $sequential_tests{$i};
	my $running = $children->nChildren() + 1; # add the one we're about to start
	my $remain = $i - 1;
	print "Start test $i; $running running, $remain remain\n";
	&$starttest($i);
	while ($children->nChildren() >= $parallelism) {
	    $children->wait();
	}
    }
    while ($children->nChildren() > 0) {
	my $running = $children->nChildren();
	print "$running running, 0 remain\n";
	$children->wait();
    }
    print "All tests finished.\n";

    my @all;
    my @failed;
    for (my $i = 1; $i <= @testlist; ++$i) {
	my ($line, $testname, $status) = dbpGetTestStatus($i);
	push (@all, $line);
	if ($status eq 'Passed') {
	    die "status mismatch" unless $status[$i] == 0;
	} else {
	    die "status mismatch" unless $status[$i] == 3 << 8;
	    push(@failed, [$testname, "Testing/Parallel/$i/failure_output"] );
	}
    }

    if (@failed == 0) {
	print "Test Status:\n";
	print @all;
	exit(0);
    } else {
	system("cat $failed[0]->[1]");
	print "\n\n------\nSOME TESTS FAILED.\n", @all, "\n";
	print "Failing tests: ", join(", ", map { $_->[0] } @failed), "\n";
	print "Output from $failed[0]->[0] shown above\n";
	print "All failure data present as $build_path/Testing/Parallel/*/failure_output\n";
	exit(1);
    }
}


sub dbpStartParallelTest {
    my ($children, $info, $build_path, $config) = @_;

    print "Starting parallel test in $build_path\n";
    $info->{"running_test"} = 1;

    $children->fork(cmd => sub { dbpDoParallelTest($build_path, $config); }, 
		    exitfn => sub { $info->{"running_test"} = 0; $info->{status_test} = $_[1]; },
 		    stdout => "deptool.test.out", stderr => "deptool.test.err");

    return $build_path;
}

sub dbpStartWhich {
    my ($which, $children, $pending, $dependencies) = @_;

    for (my $i=0; $i < @$pending; ++$i) {
	my ($build_path, $type) = @{$pending->[$i]};
	next unless $type eq $which;

	my $info = $dependencies->{$build_path};

	next unless $info->{done_build};

	splice(@$pending, $i, 1);

	my $build_stamp = stampTime($build_path, "build");
	my $which_stamp = stampTime($build_path, $which);

	if ($which_stamp <= $build_stamp) {
	    aliasChdir($build_path);
	    if ($which eq 'test') {
		my $config = readConfig(projects() . "/$info->{src}");
		if ($config->{parallel_test} 
		    || (defined $config->{parallel_test_path} 
			&& &{$config->{parallel_test_path}}($build_path))) {
		    return dbpStartParallelTest($children, $info, $build_path, $config);
		}
	    }

	    print "Starting $which in $build_path\n";
	    $info->{"running_$which"} = 1;
	    $children->fork(cmd => "make $which", 
			    stdout => "deptool.$which.out", stderr => "deptool.$which.err",
			    exitfn => sub { $info->{"running_$which"} = 0; 
					    $info->{"status_$which"} = $_[1]; });
	    return $build_path;
	} else {
	    print "Up to date $which in $build_path\n";
	    $info->{"done_$which"} = 1;
	    return undef;
	}
    }
    # print "No $which active\n";
    return undef;
}

sub dbpFinishWhich {
    my ($which, $running, $dependencies) = @_;

    my $dir = $running->{$which};
    return 1 unless defined $dir;
    my $info = $dependencies->{$dir};

    die "??" unless defined $info->{"running_$which"};
    unless ($info->{"running_$which"} == 0) {
	# print "$which not done\n";
	return 1;
    }

    die "internal" unless defined $info->{"status_$which"};
    aliasChdir($dir);
    if ($info->{"status_$which"} == 0) {
	print "Finish $which of $dir.";
	my $errors = "$dir/deptool.$which.err";
	if (-s $errors == 0) {
	    print " No error output.\n";
	} else {
	    print " Error output:\n";
	    my $fh = new FileHandle($errors)
		or die "Can't open $errors for read: $!";
	    while (<$fh>) {
		print "  $_";
	    }
	    close($fh);
	}
	stamp($which);
	$info->{"done_$which"} = 1;
	$running->{$which} = undef;

	if ($which eq 'build') {
	    my ($build_stamp, $deps_done_all_installs, $out_of_date) 
		= dbpOutOfDate($dir, $dependencies, $info);
	    die "Internal error, not up to date" if $out_of_date || ! $deps_done_all_installs;
	}
	return 1;
    } else {
	print "\n";
	print "--------------------\n";
	print "ERROR: failed $which in $dir\n";
	print "-------------------- STDOUT:\n";
	system("cat deptool.$which.out");
	if (-s "deptool.$which.err") {
	    print "\n-------------------- STDERR:\n";
	    system("cat deptool.$which.err");
	}
	return 0;
    }
}

sub depBuildStandard {
    my %options = @_;
    $options{mode} = 'optimize';
    $options{tests} = 1 unless defined $options{tests};
    $options{builddir} = buildOpt();
    $options{projects} = projects();

    return depBuildParallel(\%options);
}

sub depBuildParallel {
    my ($options) = @_;

    my $projects = projects();
    my $start_src = rootSrcDir();
    $start_src =~ s!^.*/!!o;

    my $start_dir = aliasGetCwd();
    # Calculate all things we could build and their dependencies
    my %dependencies;
    my @pending = ([$start_src,'']);
    while (@pending > 0) {
	my ($src, $sub_build_type) = @{shift @pending};
	my $build_path = projectBuildPath($options->{builddir}, $src, $sub_build_type);
	next if defined $dependencies{$build_path};
	aliasChdir("$projects/$src");

	my $info = $dependencies{$build_path} = { 
	    src => $src,
	    deps => {}
	};
	
	next if $options->{local_only};
	my @vcdeps = getVCDeps(aliasGetCwd());
	foreach my $dep (@vcdeps) {
	    my ($dep_project, $dep_sub_type) = parseDependency($dep);

	    my $dep_src = "$projects/$dep_project";
	    depWalkTryCheckout($dep_project) unless -d $dep_src;

	    push(@pending, [$dep_project, $dep_sub_type]);
	    my $dep_path = projectBuildPath($options->{builddir}, $dep_project, $dep_sub_type);
	    $info->{deps}->{$dep_path} = 1;
	}
    }
    
    # reverse is a hack to classify some bits later until I can fix it to
    # estimate and order
    foreach my $build_dir (reverse sort keys %dependencies) {
	map { push(@pending, [ $build_dir, $_ ]); } qw/build test install/;
    }

    @pending = grep ($_->[1] ne 'test', @pending) unless $options->{tests};

    my %running;
    my $children = new Lintel::ProcessManager(auto_kill_on_destroy => 1);

    my $prev_pending_size = @pending;
    # Process everything we have to process.
    my $ok = 1;

    while (@pending > 0 || $children->nChildren() > 0) {
	if ($ok) {
	    unless (defined $running{build}) {
		$running{build} = dbpStartBuild($children, \@pending, \%dependencies);
	    }
	    foreach my $which (qw/install test/) {
		next if defined $running{$which};
		$running{$which} = dbpStartWhich($which, $children, \@pending, \%dependencies);
	    }
	} else {
	    last if $children->nChildren() == 0;
	}

	if (@pending == $prev_pending_size) {
	    # only wait if we couldn't get anything removed
	    die "Not making progress, no children ok=$ok; '$pending[0]->[1]' '$pending[0]->[0]'" 
		unless $children->nChildren() > 0;

	    my %finished = $children->wait(10);

	    if (scalar keys %finished == 0) {
		print "Waiting on:\n";
		foreach my $which (qw/build install test/) {
		    next unless defined $running{$which};
		    my $dir = $running{$which};
		    my $fh = new FileHandle "$dir/deptool.$which.out"
			or die "Can't open $dir/deptool.$which.out for read: $!";
		    $dir =~ s!^.*/!!o;
		    my $lastline = '';
		    while (<$fh>) {
			$lastline = $_;
		    }
		    chomp $lastline;
		    print "  $which in $dir: $lastline\n";
		}
	    } else {
		foreach my $which (qw/build install test/) {
		    unless (dbpFinishWhich($which, \%running, \%dependencies)) {
			print "Failed on $which in $running{$which}\n";
			$ok = 0;
		    }
		}
	    }
	}
	$prev_pending_size = @pending;
    }

    unless ($ok) {
	print "Exiting on error, check previous output for precise problem.\n";
	exit(1);
    }

    aliasChdir($start_dir); # TODO: figure out why this isn't already happening, we can be left in the wrong dir
    return %$options;
}

##### Set pin

=pod

=head2 pin I<revision>

Occasionally someone will publish an update to a project that works
for that project, but breaks a project that depends on it.  If they
didn't test that project, then builds will fail until the software is
repaired.  In order to work around this problem, you can pin the
revision back to the one that used to work.  This command only works
in a source directory.  If the current source directory isn't at the
specified revision, then it will update to the specified revision.
The pin will remain until the head revision for the project changes,
as the assumption is that when the head revision changes it has fixed
the bug.

=cut

sub setPin {
    die "Have unknown files; setpin is disallowed"
        if depCommitHaveUnknown();
    die "Have changes; setpin is disallowed"
        if depCommitHaveChanges();
    my @heads = getCurHeads();
    die "Have multiple heads; setpin is disallowed"
        unless @heads == 1;
    my($revision) = @ARGV;

    if (defined $revision) {
        runCommand("mtn","update","-r",$revision);
    }

    $revision = getCurRevision()
        unless defined $revision;
    
    my $filename = depPinFilename();
    my $fh = new FileHandle ">>$filename"
        or die "Unable to open $filename for append: $!";
    print $fh "$heads[0] $revision\n";
    print "Pinning to $revision so long as head remains at $heads[0]\n";
    close($fh);
}

##### Dependency pull

=pod

=head2 pull [--unsafe]

If you want to update your local repositories and projects, but aren't yet
ready to make your changes available or just want changes other people have
made, then pull is the command you want to use.  Pull will walk all of the
directories dependent on your current directory and will pull data from the
central server and then update the local directory.  If you happen to have
outstanding changes, pull will normally perform a commit before doing the
update so that you wouldn't accidentally destroy your current changes.  If you
are sure that you want to pull despite having changes, you can use the --unsafe
option.

=cut

sub depPull {
    my %options;

    my $ret = GetOptions("unsafe!" => \$options{unsafe_pull_with_changes});
    usage("unknown options to pull") unless $ret;

    depWalk(sub { depPullCheckClean(\%options) },
	    sub { depPullOne(\%options); }, 0);
}

### sets $options->{made_changes} if we made changes.

sub depPullOne {
    my($options) = @_;

    depCommitOne() unless $options->{unsafe_pull_with_changes};
    mtnOp("pull");
    depPullMerge();
    depPullUpdate($options);
}

sub depPullMerge {
    while(1) {
        my $fh = new FileHandle "mtn automate heads |";
        my @heads = getCurHeads();
        last if @heads == 1;
        my $cwd = aliasGetCwd();
        print "\n" x 5, "You have multiple heads in $cwd.";
        userPrompt("merge the heads");
        runCommand("mtn","merge");
    }
}

sub depPullUpdate {
    my($options) = @_;

    my $cwd = aliasGetCwd();
    my $cur_rev = getCurRevision();
    my $deppin_filename = depPinFilename();
    if (-f $deppin_filename) {
        my @heads = getCurHeads();
        die "??" unless @heads == 1;

        if (foundPin($cur_rev, $heads[0])) {
	    print << "END";
****
  You are currently pinned to revision $cur_rev
  The head revision has not changed, so the pin remains.
  To remove the pin, edit $deppin_filename
****
END
            return;
        } elsif (hadPin($cur_rev)) {
            print <<"END";
****
You would be pinned to $cur_rev, but the head
has been updated.  To reset the pin:
cd $cwd; deptool pin $cur_rev
****
END
            # skip prompting, will do so for the update.
        }
    }
    while(1) {
        my $cur_rev = getCurRevision();
        my @heads = getCurHeads();
        die "??" unless @heads == 1;
        last if $cur_rev eq $heads[0];
        print <<"END";
You current checkout is not up to date in $cwd.
$cur_rev != $heads[0]
END
        userPrompt("update to the current revision");
        runCommand("mtn","update");
        $options->{made_changes} = 1;
    }
}

sub foundPin {
    my($rev, $head) = @_;

    my $filename = depPinFilename();
    return 0 unless -r $filename;
    my $fh = new FileHandle($filename)
        or die "Can't open $filename for read: $!";
    while(<$fh>) {
        return 1 if /^$head $rev$/;
    }
    return 0;
}

sub hadPin {
    my($rev) = @_;

    my $filename = depPinFilename();
    return 0 unless -r $filename;
    my $fh = new FileHandle($filename)
        or die "Can't open $filename for read: $!";
    while(<$fh>) {
        return 1 if /$rev$/;
    }
    return 0;
}

sub getCurHeads {
    my($fh) = new FileHandle("mtn automate heads |")
        or die "Unable to fork: $!";
    my @heads = <$fh>;
    close($fh);
    die "??" unless @heads > 0;
    grep(chomp, @heads);
    return @heads;
}

sub getCurRevision {
    my($fh) = new FileHandle("mtn automate get_base_revision_id |")
        or die "Unable to fork: $!";

    local $_ = <$fh>;
    die "??" unless $_ =~ /^[a-fA-F0-9]{40}$/o;
    chomp;
    close($fh);
    return $_;
}

sub depPinFilename {
    return "$ENV{HOME}/.monotone/deptool-version-pins";
}

sub depPullCheckClean {
    my ($options) = @_;

    return if $options->{unsafe_pull_with_changes};
    my $cwd = aliasGetCwd();

    if (depCommitHaveUnknown()) {
	die "You have unknown files in $cwd
Requiring you to commit first. Aborting.\n";
    }
    if (depCommitHaveChanges()) {
	die "You have uncommitted changes in $cwd
Requiring you to commit first. Aborting.\n";
    }
}

##### Dependency commit

=pod

=head2 commit [--no-tests]

If you have a set of changes that are sufficiently complete to pass
all the tests, but not yet ready for publishing, then you can run
deptool commit in order to commit all of the changes you have made as
well as any changes in dependent projects.  Commit will first run all
of the tests to verify that the changes are internally consistent.

=cut

sub depCommit {
    my %options = ('tests' => 1);
    my $ret = GetOptions("t|tests!" => \$options{tests});
    usage("unknown option to commit") unless $ret;

    %options = depBuildStandard(%options);
    depWalk(sub { }, sub { depCommitOne(%options); }, 0);
}

sub depCommitOne {
    my %options = @_;
    my $cwd = aliasGetCwd();

    die "depcommit: ERROR missing _MTN directory in $cwd"
        unless -d "_MTN";
    depCommitUnknown();
    depCommitDoCommit(%options);
}

sub ignoresFileName() {
    return "$ENV{HOME}/.monotone/deptool-commit-ignores";
}

sub depCommitUnknown { 
    my $cwd = aliasGetCwd();
    # TODO: check to make sure that we properly add recursive subdirectories;
    # there seemed to be a bug in this.  Unknown if moving the
    # haveUnknown/getUnknown bits into the while loop will fix it.
    while(1) {
	return unless depCommitHaveUnknown();
	my @unknown = depCommitGetUnknown();

        print "You have un-added files in $cwd:\n";
        print @unknown;
        print "\nDo you want to ignore or add them [no-default]?";
        $_ = <STDIN>; 
        chomp;
        if ($_ eq 'ignore') {
            my $sha1 = hexDigest(join('',@unknown));
            my $ignores_name = ignoresFileName();
            my $fh = new FileHandle ">>$ignores_name"
                or die "Can't open $ignores_name: $!";
            print $fh "$cwd $sha1\n";
            close($fh);
            return;
        } elsif ($_ eq 'add') {
            print "Adding files...\n";
            runCommand("mtn","add","--unknown");
            return;
        } else {
            print "Expected 'ignore' or 'add', not '$_'; try again\n";
        }
    }
}

sub depCommitHaveUnknown {
    my @unknown = depCommitGetUnknown();

    return 0 if @unknown == 0;
    my $fh = new FileHandle ignoresFileName();
    if ($fh) {
        my $cwd = aliasGetCwd();
        my $sha1 = hexDigest(join('', @unknown));
        while(<$fh>) {
            return 0 if $_ eq "$cwd $sha1\n";
        }
    }

    return 1;
}

sub depCommitGetUnknown {
    my $fh = new FileHandle "mtn list unknown |"
        or die "bad fork mtn: $!";
    my @unknown = <$fh>;
    close($fh);
    die "?? mtn" if $?;

    return @unknown;
}

sub depCommitHaveChanges {
    my $fh = new FileHandle "mtn diff |"
        or die "fork fail: $!";
    $_ = <$fh>;
    return 1 unless /^\#\s*$/o;
    $_ = <$fh>;
    return 1 unless /^\# no changes\s*$/o;
    $_ = <$fh>;
    return 1 unless /^\#\s*$/o;
    $_ = <$fh>;
    return 1 if defined $_;
    return 0;
}

sub depCommitDoCommit {
    my %options = @_;
    my $cwd = aliasGetCwd();
    my $first_time = 1;
    while(1) {
        if (!depCommitHaveChanges()) {
            print "depcommit: no changes in $cwd\n"
                if $first_time;
            return;
        }

        $auto_yes_to_prompts = 0 unless $first_time;
        $first_time = 0;
        print "depcommit: you have uncommitted differences in $cwd
depcommit: will show differences after successful build\n";
        userPrompt("build");
        depBuildStandard(%options);
        print "\n" x 20;
        aliasChdir($cwd);
        runCommand("mtn","diff");
        print "\ndepcommit: You have uncommitted differences (shown above) in $cwd\n";
        userPrompt("commit changes");
        eval { runCommand("mtn","commit"); };
        if ($@) {
            die "$@" if $@ !~ /mtn commit.*failed/o;
            warn "$@"; # redundant?
        }
    }
}

##### runCMake

=pod

=head2 cmake

This command has to be run in either the build or debug directory.  In the
build directory, it will set the install prefix to $BUILD_OPT and the cmake
build type to RelWithDebInfo.  In the debug directory, it will set the install
prefix to $BUILD_DEBUG and the cmake build type to Debug.  If you are in a
sub-type build directory (see cdopt), then the deptool cmake command will
automatically add -DBUILD_SUBDIR=I<sub-type> to the cmake instantiation so that
the configuration can take into effect the sub-type.  You can set the
environment variable DEPTOOL_CMAKE_FLAGS if there are additional flags that
need to be passed to cmake.

=cut

sub runCMake {
    my $clean = 0;
    Getopt::Long::Configure('pass_through');
    my $result = GetOptions("clean!" => \$clean);
    usage("Unknown argument to runCMake") unless $result;

    if ($clean) {
	usage("unexpected extra arguments") unless @ARGV == 0;
    } elsif (defined $ARGV[0] && $ARGV[0] eq 'clean') {
	usage("unexpected extra arguments") unless @ARGV == 1;
        runCMakeClean();
    } else {
        runCMakeConfig(@ARGV);
    }
}

sub runCMakeClean {
    my $cwd = aliasGetCwd();
    my $projects = projects();
    my $debug = buildDebug();
    my $opt = buildOpt();

    die "Will not clean unless under projects, debug or optimize dir"
        unless $cwd =~ m!^(($projects)|($debug)|($opt))/!o;
    print "Cleaning cmake files out of $cwd\n"
        unless $quiet;
    my @files;
    my @dirs;
    find(sub { push(@files, $File::Find::name) if /^CMakeCache.txt$/o
                   || /^Makefile$/o;
               push(@dirs, $File::Find::name) if /^CMakeFiles$/o; },
         $cwd);
    unlink(@files) == scalar @files
        or die "Unable to unlink one of @files: $!";
    rmtree(\@dirs);
    map { die "unable to delete $_" if -d $_ } @dirs;
    return 0;
}

sub runCMakeConfig {
    my @extra_args = @_;

    my $cwd = aliasGetCwd();
    my ($src, $build_subdir) = srcDir();
    my $debug = buildDebug();
    my $opt = buildOpt();

    die "Unable to find expected deptool.config file in $src"
        unless -f "$src/deptool.config";

    my @cmakecmd = ('cmake');
    if ($cwd =~ /^$debug/o) {
        push(@cmakecmd, "-D", "CMAKE_INSTALL_PREFIX=$debug", "-D",
             "CMAKE_BUILD_TYPE=Debug");
    } elsif ($cwd =~ /^$opt/o) {
        push(@cmakecmd, "-D", "CMAKE_INSTALL_PREFIX=$opt", "-D",
             "CMAKE_BUILD_TYPE=RelWithDebInfo");
    } else {
        die "Not under optimize or debug directory; aborting";
    }

    if (defined $build_subdir) {
        push(@cmakecmd, "-D", "BUILD_SUBDIR=$build_subdir");
    }
    push(@cmakecmd, @extra_args);
    if (defined $ENV{DEPTOOL_CMAKE_FLAGS}) {
	push(@cmakecmd, split(/\s+/o, $ENV{DEPTOOL_CMAKE_FLAGS}));
    }
    push(@cmakecmd, $src);
    eval { runCommand(@cmakecmd) };
    if ($@) {
	my $err = $@;

	warn $err;
	my $dep_info = "$src/doc/dependencies.txt";
	if (-r $dep_info && -f $dep_info) {
	    my $fh = new FileHandle $dep_info
		or die "Unable to open $dep_info for read: $!";
	    my $os = operatingSystem();
	    my @deps;
	    while (<$fh>) {
		next unless /^\S.*\($os\):/o;
		push(@deps, $_);
		while (<$fh>) {
		    last unless /^\s+/o || /^$/o;
		    push(@deps, $_);
		}
		last;
	    }
	    close($fh);
	    if (@deps > 0) {
		print STDERR "\ncmake failed. You may be missing required dependencies.\n";
		print STDERR "From $dep_info:\n\n";
		print STDERR @deps;
	    }
	}
	exit(1);
    }
}

##### Monotone operations

=pod

=head2 mtnpull

Run the appropriate mtn pull command for the current directory.  The
command will automatically use the right database and branch based on
the current directory, and can be run in both the source directory and
the build directory.  Does not update the current directory, and does
not run for dependencies.

=head2 mtnpush

Run the appropriate mtn push command for the current directory.  The
command will automatically use the right database and branch based on
the current directory, and can be run in both the source directory and
the build directory.  Does not update the current directory, and does
not run for dependencies.

=head2 mtnsync

Run the appropriate mtn sync command for the current directory.  The
command will automatically use the right database and branch based on
the current directory, and can be run in both the source directory and
the build directory.  Does not update the current directory, and does
not run for dependencies.

=cut

sub mtnOp {
    my($op) = @_;

    die "??" unless $op =~ /^((pull)|(push)|(sync))$/o;
    my $src = rootSrcDir();
    my %mtn_opts = readMtnOptions($src);
    my $branch = $mtn_opts{branch};
    my $database = $mtn_opts{database};

    die "? no branch" unless defined $branch;
    die "? no database" unless defined $database;

    my $syncbranch = $branch;
    $syncbranch =~ s!^(.*/.*)/.*$!$1!o;
    my $server = mtnServer();
    runCommand("mtn","-d",$database,$op,$server,"$syncbranch*");
    runCommand("mtn","-d",$database,'heads','-b',$branch);
}

=pod

=head2 mtnserve

Run the mtn serve command with the appropriate database based on the
current directory.

=cut

sub mtnServe {
    my $src = rootSrcDir();
    my %mtn_opts = readMtnOptions($src);
    die "? no database" unless defined $mtn_opts{database};

    local $_ = vcVersion();
    my $vcver = "$_->{type}-$_->{version}";
    if ($vcver =~ /^monotone-0.28\b/o) {
	runCommand("mtn","-d",$mtn_opts{database},'serve','*');
    } elsif ($vcver =~ /^monotone-0.4\d\b/o) {
	runCommand("mtn","-d",$mtn_opts{database},'serve');
    } else {
	die "Don't know how to run serve on $vcver";
    }
}

##### depPublish

=pod

=head2 publish

The publish command is the core logic for making changes globally
available.  It performs the following steps:

  made_changes = true
  while made_changes {
      made_changes = false
      Build and test (C<deptool build -t>)
      Commit any local changes (C<deptool commit>)
      Pull from the central server (C<deptool pull>)
      if made_changes == false {
          Synchronize with the central server 
          # if we got changes here, print a warning before continuing
      }
  }

Normally, before you can publish you will need to get authorization at the
central server.  In order to do so, for monotone, you would run C<mtn pubkey>
I<email-address> and send the result to the appropriate administrator.

=cut

sub depPublish {
    my $ret = GetOptions(); # No valid options
    usage("unknown option to publish") unless $ret;

    print "deppublish: committing any outstanding changes\n";
    print "  cwd = ", aliasGetCwd(), "\n" if $debug;
    depCommit();
    print "  cwd = ", aliasGetCwd(), "\n" if $debug;
    my %options = ('made_changes' => 1);
    while ($options{made_changes}) {
        $options{made_changes} = 0;
        print "deppublish: verifying current version passes regression tests\n";
        depBuildStandard();
        print "deppublish: pulling in any remote changes\n";
	print "  cwd = ", aliasGetCwd(), "\n" if $debug;
        depWalk(sub { }, sub { depPullOne(\%options); }, 0);

        unless ($options{made_changes}) {
            print "\n" x 5;
            print <<"END";
*** Running the sync.  In the unlikely case that you get any updates, you ***
*** need to get them tested and synchronized quickly because they made it ***
*** out so other people can see them. ***
END
	    print "  cwd = ", aliasGetCwd(), "\n" if $debug;
            depWalk(sub { }, sub { depSyncOne(\%options); }, 0);
            print "****** WARNING, got changes; re-running deppublish...\n"
                if $options{made_changes};
        }
    }
}

sub depSyncOne {
    my($options) = @_;

    mtnOp("sync");
    depPullUpdate($options);
}

##### Code review diff

=pod

=head2 code-review I<revision>...

The code-review command is designed to help performing code reviews of
a set of related changes.  For a single revision, it is exactly
equivalent to running kdiff3 on all files that were changed in
I<revision>.  

If multiple revisions are specified, the first step is to build a
single diff between the parent of the earliest revision specified and
the latest revision specified.  Therefore, the code review code will
first sort the revisions by the date they were committed.  Then it
will checkout the parent of the first revision.  Then for each
revision I<r> in date order, it will apply the patch between I<r> and
I<r>'s parent, which may not be the previous listed revision.
Assuming each of the patch commands succeeds, the resulting directory
will be the equivalent of just applying the updates specified by the
revisions in order.  

If one of the patches does not succeed, the code review will prompt
the user to make a repair patch, in particular by creating the file
that should have been created.  The code review tool with then store
the additional patch in /tmp so that it can be re-applied if
necessary.

Regardless, eventually a pair of directories will be created, the
first being the parent of the earliest revision, and the last being
the result of applying all of the patches for each revision and any
recovery patches.  The code review tool then will proceed to review
each of the files that have changed.  It will sort the files such that
cmake files go before others, tests come next, and then headers and
c++ files in alphabetical order.  The user can override this default
order by creating the file /tmp/diff-order-I<last-revision>.txt,
usually by starting with the one specified.

The tool will then prompt for a command.  Commands include:

=over

=item auto

automatically move onto the next step until we get to the end, or the
diff ordering file changes.

=item files

print a list of all the files that are going to be compared

=item exit 

stop the code review; do not clean up temporary files.

=item finish

stop the code review; clean up all temporary files.

=item help

get help usage

=item I<filename-substring>

select the unique filename that matches I<filename-substring> to be
reviewed next, or if multiple files match, then print out an error
message.

=back

Usually users will just hit return to bring up the kdiff3 window for
comparing the two files until they get to the end.  They can
alternately use the auto command to skip having to hit return.

=head3 BUGS

=over

=item *

renames currently confuse the code review tool.

=item *

should check *.patch.err file to see if we have any skipped patches,
this can occur as a result of renames and as a result of added files in
skipped revisions

=back

=cut

sub codeReview {
    my @revisions = @ARGV;

    my $root_src_dir = rootSrcDir();
    aliasChdir($root_src_dir);
    die "No revisions specified." if @revisions == 0;

    eval 'use File::Copy::Recursive "rcopy";';
    die "aptitude install libfile-copy-recursive-perl?\n$@" if $@;
    my %parents;
    my %dates;
    my $branch;
    foreach my $revision (@revisions) {
        my @output = vcLogRevision($revision);

        my %info = simpleParse(\@output, 
                               [ qr/^-+$/o => undef,
                                 qr/^Revision: (\S+)$/o => 'revision',
                                 qr/^Ancestor: (\S+)$/o => 'ancestor',
                                 qr/^Author:/o => undef,
                                 qr/^Date: (\S+)$/o => 'date',
				 qr/^Branch: (\S+)$/o => 'branch' ]);
        
        $parents{$info{revision}} = $info{ancestor};
        $dates{$info{revision}} = $info{date};
	$branch = $info{branch} unless defined $branch;
	unless($branch eq $info{branch}) {
	    userPrompt("continue through mismatch on branches for specified revisions?\n ($branch != $info{branch})");
	    $branch = $info{branch};
	}
    }

    @revisions = sort { $dates{$a} cmp $dates{$b} } keys %parents;

    my $basedir = "/tmp/code-review-" . getpwuid($UID);
    my $original_dir = $parents{$revisions[0]};
    my $final_dir = $revisions[@revisions - 1];
    if (-d $basedir && -d "$basedir/$original_dir" &&
        -d "$basedir/$final_dir" && -f "$basedir/diff-order") {
        print "$basedir already exists, as do the relevant
first and last revisions and the diff-order file.  
Assuming you just want to continue editing.\n";
    } elsif (-d $basedir) {
        print "Missing expected files to continue diffing in $basedir\n";
        print "Return to delete, ctrl-c to abort: ";
        $_ = <STDIN>;
        runCommand("rm -rf $basedir");
    }

    if (! -d $basedir) {
        mkdir($basedir, 0755) or die "unable to mkdir $basedir: $!";
        codeReviewSequence(\@revisions, \%parents, $basedir);
    } else {
        kdiffDirs($basedir, $original_dir, $final_dir, \@revisions);
    }
}

sub codeReviewSequence {
    my ($revs, $parents, $basedir) = @_;

    my @revisions = @$revs;
    my %mtn_options = readMtnOptions();
    my $database = $mtn_options{database};
    die "missing db in .../_MTN/options" 
        unless defined $database;
    
    my $start = $parents->{$revisions[0]};

    print "Trying to build single sequence diff from ", 
      substr($start,0,20), " to ", substr($revisions[@revisions-1],0,20), 
      "\n  using ", join(", ", map { substr($_, 0, 8) } @revisions), "\n";

    codeReviewCheckout($database, "$basedir/$start", $start);
    
    my $last = $start;
    while (@revisions > 0) {
        my $to = $revisions[0];
        my $from = $parents->{$to};

        print "Trying to patch $last\n   with ", substr($from, 0, 20), 
            " -> ", substr($to, 0, 20), "\n";

        codeReviewPatch($database, $basedir, $last, $from, $to);
        $last = $to;
        shift @revisions;
    }

    print "Successfully built single sequence for review.\n";

    makeDiffOrder($basedir, $start, $last);
    kdiffDirs($basedir, $start, $last, $revs);
}

# TODO-sprint: make .thrift files show up early by default.
sub makeDiffOrder {
    my ($basedir, $original_dir, $final_dir) = @_;

    my $reference_file = "/tmp/diff-order-$final_dir.txt";
    if (-f $reference_file) {
        print "$reference_file exits; just using it.\n";
        copy($reference_file, "$basedir/diff-order")
            or die "copy failed: $!";
        return;
    }
    my @changed = getChanged($basedir, $original_dir, $final_dir);

    my %file_key;
    map { die "?? $_" unless m!^(.+/)?([^/]+?)(?:\.(\w+))?$!o;
          my ($dir, $name, $suffix) = ($1, $2, $3);
	  $dir ||= '';
	  $suffix ||= 'no-suffix';
          my $test_key = $dir =~ m!/tests\b!o ? 0 : 1;
	  my $thrift_key = $suffix eq 'thrift' ? 0 : 1;
          my $header_key = $suffix eq 'hpp' ? 0 : 1;
          my $cmake_key = $name =~ /^CMake/o ? 0 : 1;
          
          # sort cmake files first, then tests, then by filename 
          # sorting headers before sources.
          
          $file_key{$_} = "$cmake_key-$test_key-$name-$header_key";
      } @changed;
    @changed = sort { $file_key{$a} cmp $file_key{$b} } @changed;
    
    my $fh = new FileHandle ">$basedir/diff-order"
        or die "bad";
    print $fh join("\n", @changed), "\n";
    close($fh);

    print "store this file as $reference_file to automatically use it.";
    print "Changed:\n", join("\n", @changed), "\n";
}

sub kdiffDirs {
    my ($basedir, $original_dir, $final_dir, $revisions) = @_;

    # TODO-sprint: make this extract the relevant part from each log
    # message for the file we are reviewing.

    foreach my $rev (@$revisions) {
        print vcLogRevision($rev); 
    }
    my $cur = '*start*';
    my $auto = undef;
    while(1) {
        print "\n";
        print "------------------------------------------------------------\n";
        print "Last file diffed: $cur\n";
        my $next = getNextDiffFile($basedir, $cur);
        print "Current next file to diff: $next\n";
        print "Editable diff ordering file: $basedir/diff-order\n";
        my $default = "diff $next";
        $default = "finish" if $next eq '*end*';
        print "commands: auto, files, exit, finish, help\n";
        print "Enter filename substring or command [$default]: ";
        if (defined $auto && (-M "$basedir/diff-order") == $auto) {
            print "[auto]\n";
            $_ = '';
        } else {
            $_ = <STDIN>;
            chomp;
        }
        $_ = 'finish' if $_ eq '' && $default eq 'finish';
        if ($_ eq '') {
            my $check_next = getNextDiffFile($basedir, $cur);
            if ($check_next ne $next) {
                print "\n***ordering file changed***\n";
                redo;
            }
            my $original = "$basedir/$original_dir/$next";
            my $final = "$basedir/$final_dir/$next";
            unless (-f $original) {
                print "Assuming $final is new file, creating empty temporary\n";
		my ($dir, $file) = $original =~ m!^(.+)/([^/]+)$!o;
		unless (-d $dir) {
		    mkpath([$dir], 0, 0777);
		    die "?" unless -d $dir;
		}
                my $fh = new FileHandle ">$original"
                    or die "bad: $!";
                close($fh);
            }
            if (! (-f $original && -f $final)) {
                warn "$original or $final missing; looping";
                $auto = undef;
                redo;
            }
            eval {
                runCommand('kdiff3','--L1', "original ($next)", '--L2', "new ($next)", 
                           "$basedir/$original_dir/$next", 
                           "$basedir/$final_dir/$next");
            };
            # warn "kdiff3 command failed (ignoring)" if $@;
            $cur = $next;
        } elsif ($_ eq 'auto') {
            $auto = -M "$basedir/diff-order";
        } elsif ($_ eq 'files') {
            my @files = getDiffOrder($basedir);
            print "\n\nFiles:\n", join("\n", @files), "\n";
        } elsif ($_ eq 'exit') {
            last;
        } elsif ($_ eq 'finish') {
            runCommand("rm -rf $basedir");
            last;
        } elsif ($_ eq 'help') {
            print <<"END_OF_HELP";

auto: skip the prompt for a command until the next file to diff changes
files: list the files we will diff.
exit: exit from deptool code-review-diff
finish: delete the code review temporary directories and exit
help: show this help
*: try to find a file with this as a substring and diff it next.
END_OF_HELP
        } else { 
            $cur = selectPrevDiffFile($basedir, $_, $cur);
        }
    }
}

sub getChanged {
    my ($basedir, $start, $last) = @_;

    my @old_files = findFilesPrefix("$basedir/$start");
    my @new_files = findFilesPrefix("$basedir/$last");
    die "??" if @new_files == 0;
    my @changed;
    my %old;
    map { $old{$_} = 1 } @old_files;
    map { 
        if (defined $old{$_}) {
            ++$old{$_};
            my $old = "$basedir/$start/$_";
            my $new = "$basedir/$last/$_";
            if (-d $old && -d $new) {
                # ignore
            } else {
                die "? $_" if -d $old || -d $new;
                push(@changed, $_) unless compare($old, $new) == 0;
            }
        } else {
            push(@changed, $_)
                unless -d "$basedir/$last/$_" || /\.orig$/o || /\.rej$/o;
        }
      } @new_files;

    while(my($k,$v) = each %old) {
        die "old file $k missing" unless $v == 2;
    }

    @changed = grep(!/((-final-version)|(-pre-fix))$/o, @changed);
    return @changed;
}

sub getNextDiffFile {
    my($basedir, $cur) = @_;

    my @order = getDiffOrder($basedir);
    return $order[0] if $cur eq '*start*';
    for(my $i=0; $i < @order; ++$i) {
        if ($order[$i] eq $cur) {
            return '*end*' if $i + 1 == @order;
            return $order[$i+1];
        }
    }
    return "**ERROR: Unable to find file $cur";
}

sub selectPrevDiffFile {
    my ($basedir, $target, $cur) = @_;

    my @order = getDiffOrder($basedir);
    my @match = grep(/$target/, @order);
    if (@match == 0) {
        print "\n\n************\nNo match for $target found. Choices:\n", 
            join("\n", @order), "\n";
        return $cur;
    } elsif (@match > 1) {
        print "\n\n************\nMultiple matches for $target found:\n",
            join("\n", @match), "\n";
        return $cur;
    } else {
        for(my $i=0; $i < @order; ++$i) {
            if ($order[$i] eq $match[0]) {
                return "*start*" if $i == 0;
                return $order[$i-1];
            }
        }
        die "??";
    }
}

sub getDiffOrder {
    my($basedir) = @_;

    my $fh = new FileHandle "$basedir/diff-order"
        or die "Can't open $basedir/diff-order for read: $!";
    my @order = <$fh>;
    close($fh);
    grep(chomp, @order);

    return @order;
}

sub getCmdOutput {
    my($cmd) = @_;

    my $fh = new FileHandle "$cmd 2>/dev/null |" 
        or die "Unable to run $cmd: $!";
    my @ret = <$fh>;
    close($fh) or confess "close failed: $!\ncommand is $cmd";
    die "$cmd failed" unless $? == 0;
    return @ret;
}

sub simpleParse {
    my($data, $matches) = @_;

    my %ret;

    # print join(", ", @$matches);
    die "bad parse" unless @$data >= @$matches;
    for(my $i=0; $i < @$matches/2; ++$i) {
        local $_ = $data->[$i];
        chomp;
        my $match = $matches->[2*$i];
        my $var = $matches->[2*$i+1];

        die "?? $i" unless defined $match;
        die "Error on line $i expected $match, got '$_'"
            unless /$match/;
        $ret{$var} = $1 if defined $var;
    }
    return %ret;
}

sub codeReviewCheckout {
    my($database, $targetdir, $revision) = @_;

    quietRunCommand('mtn', 'checkout', '-d', $database, 
                    '-r', $revision, $targetdir);
}

sub codeReviewPatch {
    my ($database, $basedir, $last, $from, $to) = @_;

    rcopy("$basedir/$last", "$basedir/$to")
        or die "copy ($basedir/$last,$basedir/$to) failed: $!";
    quietRunCommand("mtn diff -d $database -r $from -r $to >$basedir/$to.patch");
    eval {
        quietRunCommand("patch -U -p0 --ignore-whitespace -d $basedir/$to <$basedir/$to.patch >$basedir/$to.patch.err 2>&1");
    };
    if ($@) {
        my @failed = grep(/\.rej$/o, findFilesPrefix("$basedir/$to"));
        print "\n\n**************\n";
        print "Patch failed for files: ", join(", ", @failed), "\n";

        foreach my $file (@failed) {
            my $patch = $file;
            $file =~ s/\.rej$//o;
            my $repairpatch = $file;
            $repairpatch =~ s!/!_!go;
            $repairpatch = "/tmp/repair-$to-$repairpatch";
            if (-f $repairpatch) {
                print "$repairpatch exists; will just apply\n";
                runCommand("patch -p4 -d $basedir/$to < $repairpatch");
            } else {
                print "will start $ENV{EDITOR} for $file and rejected patch\n";
                print "return to continue, ctrl-c to abort: ";
                $_ = <STDIN>;
                copy("$basedir/$to/$file","$basedir/$to/$file-pre-fix");
                runCommand("mtn cat -r $to $file >$basedir/$to/$file-final-version");
                runCommand("$ENV{EDITOR} $basedir/$to/$file $basedir/$to/$patch $basedir/$to/$file-final-version");
                if (compare("$basedir/$to/$file-pre-fix","$basedir/$to/$file") == 0) {
                    print "No changes made.  Return to save empty patch, ctrl-c to abort: ";
                    $_ = <STDIN>;
                }

                print "Saving repair difference as $repairpatch\n";
                eval { runCommand("diff -u $basedir/$to/$file-pre-fix $basedir/$to/$file >$repairpatch"); };
            }
            unlink("$basedir/$to/$file-pre-fix", "$basedir/$to/$patch",
                   "$basedir/$to/$file-final-version");
        }
    }
}

sub findFilesPrefix {
    my ($prefix) = @_;

    my @ret;
    find(sub { local $_ = $File::Find::name;
               die "??" unless s,^$prefix\b/?,,;
               push(@ret, $_); }, $prefix);
    return @ret;
}

##### Change Directory functions 
# Actually just prints out what has to happen such that eval of returned string
# in bourne shells will change the directory.

=pod

=head2 cdsrc I<cwd>

The source and build directories maintain parallel structure.
Therefore if you are currently in $BUILD_OPT/Lintel/src/tests, it can
be useful to jump to $PROJECTS/Lintel/src/tests.  The cdsrc command
will print out the shell command necessary to make this switch.
Therefore you probably want an alias along the lines of:

    s () { eval `$DEPTOOL cdsrc $PWD` }

to make it easier to type the command in.  The s command will deal
correctly with sub-build-type directories except it will get confused
if you have a source directory named project-something.


=head2 cdopt I<cwd> [I<build-type>]

The cdopt command performs the reverse jump from cdsrc, it moves from
a position under $PROJECTS to one under $BUILD_OPT.  The build-type
optional argument allows you to have multiple directories that all
build from the source directory with different build options.  Since
deptool wants to remember the build type for each directory, it
actually prints out a command that sets the environment variable for
the build-type if needed.  An alias along the lines of:

    b () { eval `$DEPTOOL cdopt $PWD "$@"` }

will make it easier to issue this command.  Unfortunately because of
the environment setting, this command only works with bourne-shells
right now.  If you specify '' as the build type, it will remove the
build type from whatever directory you are currently in.

=head2 cddebug

The cddebug command is the same as cdopt, except it takes you to the
debug directory.  The natural alias is therefore: 

    d () { eval `$DEPTOOL cddebug $PWD "$@"` }

=cut

sub cdSrc {
    my $cwd = cdInitialPrep(1, 'cdsrc <cur-working-dir>');
    
    my ($project, $subprojdir, $buildtype) = divideDir($cwd);
    $subprojdir ||= '';
    my $srcdir = "$ENV{PROJECTS}/$project$subprojdir";
    if (-d $srcdir) {
        print "cd $srcdir\n";
        exit(0);
    } else {
        print "echo '$srcdir does not exist'\n";
        exit(1);
    }
}

sub cdBuild {
    my($what) = @_;

    my $cwd = cdInitialPrep(2, "cd${what} <cur-working-dir> [build-type] -- type defaults to previous; use '' to reset.");

    my ($project, $subprojdir, $buildtype) = divideDir($cwd);
    $subprojdir ||= '';
    $buildtype ||= '';

    my $cleanproj = $project;
    $cleanproj =~ s/\W/_/go;

    my $deptool_env = "deptool_${cleanproj}_subbuild";
    $buildtype = $ENV{$deptool_env}
        if $buildtype eq '' && defined $ENV{$deptool_env};
    $buildtype = $ARGV[1] if @ARGV == 2;

    my $xbuildtype = $buildtype eq '' ? '' : "-$buildtype";
    my $envvar = $what eq 'opt' ? 'BUILD_OPT' : 'BUILD_DEBUG'; 
    my $builddir = "$ENV{$envvar}/$project$xbuildtype$subprojdir";
    if (! -d $builddir) {
        print STDERR "$builddir missing, creating...\n";
        mkpath($builddir) or die "Unable to mkdir $builddir: $!";
    }

    print "export ${deptool_env}=$buildtype;\n";
    print "cd $builddir\n";
}

sub cdInitialPrep {
    my ($maxargs, $usage) = @_;
    $maxargs ||= 1;
    unless (defined $ENV{PROJECTS} && defined $ENV{BUILD_DEBUG} &&
            defined $ENV{BUILD_OPT}) {
        print "echo 'can not use deptool cd operations environment is not set up'\n";
        exit(1);
    }

    unless (@ARGV >= 1 && @ARGV <= $maxargs && -d $ARGV[0]) {
        print "echo 'Usage: deptool $usage'";
        exit(1);
    }
    return $ARGV[0];
}

# TODO: combine this somehow with srcDir
# returns (project, subdir, build-type)
sub divideDir {
    my($dir) = @_;
    
    my $projects = projects();
    my $opt = buildOpt();
    my $debug = buildDebug();
    if ($dir =~ m!^$projects/([^/]+)(/.+)?$!o) {
	return ($1, $2, undef);
    } elsif ($dir =~ m!^$opt/([^/]+?)(?:-(\w+))?(/.+)?$!o) {
	return ($1, $3, $2);
    } elsif ($dir =~ m!^$debug/([^/]+?)(?:-(\w+))?(/.+)?$!o) {
	return ($1, $3, $2);
    } else {
	print "echo '$dir is not under $projects, $opt, or $debug'\n";
	exit(1);
    }
}

##### Common -- depwalk

sub depWalkRecurse ($$$$$$);

# pre_fn gets called before we recurse into the version control dependencies
# post_fn gets called after we recursed into the version control dependencies

sub depWalk ($$$) {
    my($pre_fn, $post_fn, $use_sub_build_type) = @_;

    my $src = rootSrcDir();
    depWalkRecurse($pre_fn, $post_fn, $src, {}, $use_sub_build_type, '');
}

# TODO: extend visited to instead of having just a flag to note
# visited, it's a hash map that has pre_visited, stamp => { build => ,
# test => , install => } pass the hash map into, the pre and post
# functions (make sure they have the same signature; both should take
# all three arguments); use that hash map in stampUpToDate, and
# require it to be passed in.  Inside of depWalkRecurse, initialize
# the stamp files at the beginning, set them to 0 during the two
# unlinks in depBuildCheckOld.  stamp() should also take the array,
# and should update it when it makes the utime call, and then
# stampUpToDate should only look at the array, not do stat calls on
# it's own.
#
# Probably rename visited to
# build_dir_status, possibly include dependencies in there, instead of
# as a separate array,
# e.g. $build_dir_status->{dirish}->{dependencies} = [
# build_dir_status->{depdir}->{stamp} ]

sub depWalkRecurse ($$$$$$) {
    my($pre_fn, $post_fn, $src, $visited, $use_sub_build_type, $build_type) = @_;

    if ($use_sub_build_type) {
	if (defined $visited->{"$src $build_type"}) {
	    return if $visited->{"$src $build_type"};
	}
        $visited->{"$src $build_type"} = 1;
    } else {
        return if $visited->{$src};
        $visited->{$src} = 1;
    }

    aliasChdir($src);
    &$pre_fn($build_type);
    my @vcdeps = getVCDeps($src);

    if (@vcdeps > 0) {
        my $projects = projects();
        foreach my $dep (@vcdeps) {
	    my ($project, $sub_build_type) = parseDependency($dep);

            my $depsrc = "$projects/$project";
	    depWalkTryCheckout($project) unless -d $depsrc;
            depWalkRecurse($pre_fn, $post_fn, $depsrc, $visited, $use_sub_build_type, 
			   $sub_build_type);
        }
    }
    aliasChdir($src);
    print "depwalk: running walk function in $src ($build_type)\n\n"
        unless $quiet;
    &$post_fn($build_type, \@vcdeps);
    print "\n";
}

sub depWalkTryCheckout {
    my ($dep) = @_;
    my $projects = projects();

    print "depWalk: Trying to checkout missing dependency $dep\n";
    eval {
	local @ARGV = ($dep);
	depCheckout($dep);
    };

    if ($@ && $@ =~ /No branches found matching/o) {
	depWalkTryInit($dep);
	eval {
	    local @ARGV = ($dep);
	    depCheckout($dep);
	};
    }
	
    die "Unable to find dependency $dep as $projects/$dep; depCheckout failed: $@"
	if $@;

    die "depCheckout succeeded, but missing directory??"
	unless -d "$projects/$dep";
}

sub depWalkTryInit {
    my ($dep) = @_;
    my $fh = new FileHandle "mtn list branches |"
	or die "Can't start mtn list branches: $!";
    my $uniqueifier = "unknown.example.com";
    while(<$fh>) {
	if (m!^(\w+\.[^/]+)/!o) {
	    $uniqueifier = $1;
	    last;
	}
    }
    close($fh);

    print "Unable to find dependency $dep in current monotone databases.\n";
    my $to_init = "$uniqueifier/$dep";
    print "Branch to init [$to_init]: ";
    $_ = <STDIN>;
    if (!/^\s*$/o) {
	chomp;
	$to_init = $_;
    }
    eval {
	local @ARGV = ($to_init);
	depInit();
    };
    die "depInit($to_init) failed: $@"
	if $@;
}

# TODO: combine this somehow with divideDir
sub srcDir {
    my $start = aliasGetCwd();
    my $projects = projects();
    my $debug = buildDebug();
    my $opt = buildOpt();

    local $_ = $start;
    my $build_subdir;
    if (m!^$projects/!o) { 
        # in a source directory already
    } elsif (-d "_MTN") {
        # in some kind of source directory already.
    } elsif (m!^(($debug)|($opt))/!o) {
        s!^(($debug)|($opt))/!!o;
        if (-d "$projects/$_") {
            $_ = "$projects/$_";
        } elsif (m!^(\w[^/]*)-(\w+)(/.*)$!o && -d "$projects/$1/$3") {
            $build_subdir = $2;
            $_ = "$projects/$1$3";
        } elsif (m!^(\w[^/]*)-(\w+)$!o && -d "$projects/$1") {
            $build_subdir = $2;
            $_ = "$projects/$1";
        } else {
            die "$start is under a build directory, but can't find related source dir";
        }
    } else {
        die "$_ is not under a projects or build directory";
    }
    return ($_, $build_subdir) if wantarray;
    return $_;
}

sub rootSrcDir {
    my $start = srcDir();
    local $_ = $start;
    while (! -f "$_/deptool.config") {
        s!/[^/]+$!!o;
        die "Unable to find deptool.config file anywhere under $start"
            if $_ eq '';
    }
    return $_;
}

##### Env functions

=pod

=head2 getenv I<what>

The getenv command allows you to get the environment variables that
are needed for deptool to work without prompting.  This command has
two forms, one that gets a specific environment variable and prints it
out, and one that prints out a string that can be evaluated to set all
the environment variables in the shell.  Therefore I<what> can have a
number of values:

=over

=item for-sh

Print out all of the environment variables formatted for sh-style
shells.  This command does not prompt for input, so if values are not
currently set in the environment, the defaults will be used.

=item for-csh

The same as for-sh, except for csh-based shells.

=item projects

The PROJECTS environment variable.  Specifies the root directory for
sources of projects.

=item buildRoot

The BUILD_ROOT environment variable.  Specifies the parent directory
for the optimize and debug build directories.  Unused if BUILD_OPT and
BUILD_DEBUG are set.

=item operatingSystem

The OS environment variable.  Automatically inferred by looking at
various files in /etc to determine the operating system type and
version.

=item unameM

The UNAME_M environment variable.  The result of running uname -m as
you have to build differently for different architecture types.

=item buildDebug

The BUILD_DEBUG environment variable.  Specifies the root directory
for debugging builds.  Defaults to $BUILD_ROOT/dbg-$OS-$UNAME_M, or
$BUILD_ROOT/debug if the latter exists.

=item buildOpt

The BUILD_OPT environment variable.  Specifies the root directory
for optimized builds.  Defaults to $BUILD_ROOT/opt-$OS-$UNAME_M, or
$BUILD_ROOT/optimize if the latter exists.

=item makeParallelism

The MAKE_PARALLELISM environment variable.  Defaults to ceil(1.5 *
ncores), or 1 if the number of cores can't be determined.  Useful for
C<make -j $MAKE_PARALLELISM>.

=item mtnServer

The MTN_SERVER environment variable.  Defaults to usi.hpl.hp.com.
Needed to determine the central repository for public updates.

=back

=cut

sub getEnv {
    my $result = GetOptions("quiet!" => \$quiet);
                            
    usage("Unknown error") unless $result;
    usage("Missing requested env var") unless @ARGV == 1;

    my $env = $ARGV[0];
    if ($env =~ /^for-((sh)|(csh))$/o) {
        my $shell = $1;
        $quiet = 1;
        $auto_yes_to_prompts = 1;
        
        printEnv($shell, 'PROJECTS', \&projects);
        printEnv($shell, 'BUILD_ROOT', \&buildRoot);
        printEnv($shell, 'OS', \&operatingSystem);
        printEnv($shell, 'UNAME_M', \&unameM);
        printEnv($shell, 'BUILD_DEBUG', \&buildDebug);
        printEnv($shell, 'BUILD_OPT', \&buildOpt);
        printEnv($shell, 'MAKE_PARALLELISM', \&makeParallelism);
        printEnv($shell, 'MTN_SERVER', \&mtnServer);
    } else {
        usage("Bad env var request") unless $env =~ /^\w+$/o;
        my $ret = eval "$ARGV[0]()";
        die "Unknown env var $env"
            if $@ && $@ =~ /^Undefined subroutine/o;
        die $@ if $@;
        
        print "$ret\n";
    }
}

sub printEnv {
    my($shell, $envvar, $fn) = @_;

    my $val = &$fn();
    if ($shell eq 'sh') {
        print qq{export $envvar="$val";\n};
    } elsif ($shell eq 'csh') {
        print qq{setenv $envvar "$val";\n};
    } else {
        die "?? $shell";
    }
}

sub projects {
    $Cache::projects ||= $ENV{PROJECTS};
    unless(defined $Cache::projects) {
        userPrompt("missing \$ENV{PROJECTS}; assume $ENV{HOME}/projects");
        $Cache::projects = "$ENV{HOME}/projects";
    }
    return $Cache::projects;
}

sub buildRoot {
    $Cache::build_root ||= $ENV{BUILD_ROOT};
    unless(defined $Cache::build_root) {
        userPrompt("missing \$ENV{BUILD_ROOT}; assume $ENV{HOME}/build");
        $Cache::build_root = "$ENV{HOME}/build";
    }
    return $Cache::build_root;
}

sub operatingSystem {
    $Cache::operating_system ||= $ENV{OS};
    unless(defined $Cache::operating_system) {
	if (-f "/etc/lsb-release") { # need to check this first, Ubuntu has /etc/debian_version
            my $lsbver = new FileHandle("/etc/lsb-release")
                or die "Can't open /etc/debian_version for read: $!";
	    my %info;
	    while(<$lsbver>) {
		chomp;
		die "unknown line in /etc/lsb-release '$_'"
		    unless /^([A-Z_]+)=(.+)$/o;
		$info{$1} = $2;
	    }
	    if (defined $info{DISTRIB_ID} && defined $info{DISTRIB_RELEASE}
		&& $info{DISTRIB_ID} eq 'Ubuntu' && $info{DISTRIB_RELEASE} =~ /^\d+\.\d+$/o) {
		$Cache::operating_system = "ubuntu-$info{DISTRIB_RELEASE}";
	    } elsif (defined $info{DISTRIB_ID}) {
		$Cache::operating_system = "unknown-distrib-$info{DISTRIB_ID}";
	    } else {
		$Cache::operating_system = "unknown-lsb";
	    }
	} elsif (-f "/etc/debian_version") {
            my $debver = new FileHandle("/etc/debian_version")
                or die "Can't open /etc/debian_version for read: $!";
            $_ = <$debver>;
            close($debver);
            chomp;
            if (/^(\d+\.\d+)(\.\d+)?$/o) {
                $Cache::operating_system = "debian-$1";
            } elsif (m!^([a-z]+)/sid$!o) {
                $Cache::operating_system = "debian-$1-unstable";
            } elsif (m!^testing$!o) {
                $Cache::operating_system = "debian-testing-unstable";
            } else {
                s/\W//go; s/\s/_/go;
                $Cache::operating_system = "debian-unknown-$_";
            }
        } elsif (-f "/etc/redhat-release") {
            my $rhver = new FileHandle("/etc/redhat-release")
                or die "Can't open /etc/redhat-release for read: $!";
            $_ = <$rhver>;
            close($rhver);
            chomp;
            if (/^Red Hat Enterprise Linux.+release (\d+)\b/o) {
                $Cache::operating_system = "rhel$1";
	    } elsif (/^Fedora release (\d+) \(\w+\)$/o) {
		$Cache::operating_system = "fedora$1";
            } else {
                s/\W/_/go; s/\s/_/go;
                $Cache::operating_system = "rh-unknown-$_";
            }
	} elsif (-f "/etc/SuSE-release") {
	    my $susever = new FileHandle("/etc/SuSE-release")
		or die "Can't open /etc/SuSE-release for read: $!";
	    $_ = <$susever>;
	    close($susever);
	    chomp;
	    if (/^openSUSE (\d+)\.\d+ /o) {
		$Cache::operating_system = "opensuse-$1";
	    } else {
                s/\W/_/go; s/\s/_/go;
		$Cache::operating_system = "opensuse-unknown-$_";
	    }
        } else {
            $Cache::operating_system = "unknown";
        }
        if ($Cache::operating_system =~ /unknown/o) {
            print STDERR "Unknown OS, using $Cache::operating_system\n";
	    print STDERR "Set \$OS to avoid warning, or fix deptool to auto-detect\n";
	    unless ($quiet) { # We're probably running under getEnv.
		print "Hit return to continue: ";
		$_ = <STDIN>;
	    }
        }
    }
    return $Cache::operating_system;
}

sub unameM {
    $Cache::uname_m ||= $ENV{UNAME_M};

    unless(defined $Cache::uname_m) {
        $Cache::uname_m = `uname -m`;
        chomp $Cache::uname_m;
        if ($Cache::uname_m eq '') {
            $Cache::uname_m = "arch_unknown";
            warn "Unknown architecture, using arch_unknown";
        }
    }
    return $Cache::uname_m;
}

sub buildDebug {
    $Cache::build_debug ||= $ENV{BUILD_DEBUG};
    unless(defined $Cache::build_debug) {
        my $root = buildRoot();
        if (-d "$root/debug") {
            $Cache::build_debug = "$root/debug";
        } else {
            $Cache::build_debug 
                = buildRoot() . "/dbg-" . operatingSystem() . "-" . unameM();
        }
        userPrompt("missing \$ENV{BUILD_DEBUG}; assume $Cache::build_debug");
    }
    return $Cache::build_debug;
}

sub buildOpt {
    $Cache::build_optimize ||= $ENV{BUILD_OPT};
    unless(defined $Cache::build_optimize) {
        my $root = buildRoot();
        if (-d "$root/optimize") {
            $Cache::build_optimize = "$root/optimize";
        } else {
            $Cache::build_optimize 
                = buildRoot() . "/opt-" . operatingSystem() . "-" . unameM();
        }
        userPrompt("missing \$ENV{BUILD_OPT}; assume $Cache::build_optimize");
    }
    return $Cache::build_optimize;
}

sub makeParallelism {
    my $fh = new FileHandle("/proc/cpuinfo");
    my $nprocessors = 0;
    if ($fh) {
        while(<$fh>) {
            ++$nprocessors if /^processor\s+:\s+\d+$/o;
        }
        close($fh);
    }
    if ($nprocessors == 0) {
        print "Warning: unable to find \# processors in /proc/cpuinfo\n"
            unless $quiet;
        return 1;
    }
    return POSIX::ceil($nprocessors * 1.5); # oversubscribe by 50%
}

sub mtnServer {
    $Cache::mtn_server ||= $ENV{MTN_SERVER};
    unless(defined $Cache::mtn_server) {
        userPrompt("assume default mtn server usi.hpl.hp.com (set via \$MTN_SERVER)");
        $Cache::mtn_server = "usi.hpl.hp.com";
    }
    return $Cache::mtn_server;
}

##### Common functions

# TODO-sprint: add in support for rc file, allow user to specify config name as argument
# add documentation.  Put call to readDeptoolRc back in before my %commands
#
# sub readDeptoolRc {
#     my $cfile = "$ENV{HOME}/.deptoolrc";
#     if (! $noconfig && -f $cfile && -r $cfile) {
# 	my $config = new FileHandle($cfile)
# 	    or die "Can't open $cfile for read: $!";
# 	while (<$config>) {
# 	    chomp;
# 	    next if /^\s*(#.*)?$/;   # Ignore comments and empty lines
# 	    if (/^([A-Z_]+)=(.+)$/o) {
# 		$ENV{$1} = $2;
# 	    } elsif (/^([A-Z_]+)=$/o) {
# 		delete $ENV{$1};
# 	    } else {
# 		warn "Ignoring invalid line '$_' in $cfile";
# 	    }
# 	}
# 	close($config);
#     }
# }

=pod

=head1 deptool.config

The deptool.config file at the root of the source directory for each project.
It is a perl expression that is evaluated in order to determine how to build
the project, and is used to identify the root source directory.  It includes
descriptions of dependencies, and enables control over parallel testing.  The
file is expect to return a hash reference, for example:

    {
	dependencies => [qw/Lintel DataSeries SomethingElse/],
        parallel_test => 0, # default value, disable parallel testing in general
        parallel_test_path => sub {
            # build in parallel if the build path ends in /Lintel
    	return $_[0] =~ m!/Lintel$/o; 
        }
    }

Valid options in a deptool.config file include the following.  Unknown options will
result in a warning being printed out.

=over 4

=item dependencies => [qw/project list/]

List of projects that this project depends on.  Deptool will use this to make
sure those projects are built and installed first.  It will also automatically
check them out if you are using version control.

If you want special builds in different modes, then you can list them as
'I<dependency>;I<sub-build-type>' (without the '').  This input has the same
effect as creating a dependency where you run b I<sub-build-type> and then
build in that directory.

=item parallel_test => [0|1]

Should deptool execute the tests for this directory in parallel.  The
default is 0 (no).

=item parallel_test_path => sub { my ($build_path) = @_; return 0|1; }

Given the current build path, should deptool execute tests in
parallel?  This function allows you to have parallel tests for some
build modes and not for others.

=item sequential_tests => [qr/test-name-re/,...]

Specify a list of regex's for tests that have to be run sequentially.  All of
the sequential tests will be executed before any of the parallel tests.  It is
an error for a regexp to match multiple tests or no tests.  This option has no
effect if parallel tests are not enabled.

=back

=cut

# Pass in the directory, it knows the filename.
sub readConfig {
    my ($cfg_dir) = @_;

    confess "internal $cfg_dir" unless -d $cfg_dir;

    my $cfg_path = "$cfg_dir/deptool.config";
    confess "Error: missing $cfg_path\n"
	unless -r $cfg_path;

    my $fh = new FileHandle($cfg_path)
	or die "Can not open $cfg_path for read: $!";
    # slurp mode
    local $/; 
    my $file = <$fh>;

    my $compartment = new Safe;
    my $result = $compartment->reval($file);
    die "Unable to evaluate $cfg_path: $@" if $@;
    die "Did not get a hash ref back from evaluating $cfg_path" unless ref $result eq 'HASH';

    die "Invalid parallel_test value in $cfg_path, expected 0|1, not '$result->{parallel_test}'"
	if defined $result->{parallel_test} && $result->{parallel_test} !~ /^[01]$/o;
    die "Invalid parallel_test_path value in $cfg_path\n"
	. " expected sub { }, not '$result->{parallel_test}'"
	if defined $result->{parallel_test_path} && ref $result->{parallel_test_path} ne 'CODE';
    if (defined $result->{sequential_tests}) {
	die "Invalid sequential_tests value in $cfg_path\n"
	    . " expected [...], not '$result->{sequential_tests}'"
	    unless ref $result->{sequential_tests} eq 'ARRAY';
	foreach my $elem (@{$result->{sequential_tests}}) {
	    die "Invalid sequential_tests array element in $cfg_path\n"
		. " expected qr/.../, not '$elem' --> '" . (ref $elem) . "'"
		unless (ref $elem) =~ /\bRegexp$/o;
	}
    }

    if (defined $result->{dependencies}) {
	die "Invalid dependencies value in $cfg_path\n"
	    . " expected [ ... ], not '$result->{dependencies}'"
	    unless ref $result->{dependencies} eq 'ARRAY';
	foreach my $elem (@{$result->{dependencies}}) {
	    die "Invalid dependencies array element in $cfg_path\n"
		. " expected .+(;\\w+)?, not '$elem'"
		unless $elem =~ /^.+(;\w+)?$/o;
	}
    }

    my %expect = map { $_ => 1 } qw/dependencies parallel_test parallel_test_path 
	                            sequential_tests/;
    
    foreach my $key (keys %$result) {
	warn "Unrecognized option '$key' in $cfg_path" unless $expect{$key};
    }

    return $result;
}

sub getVCDeps {
    my ($config_or_path) = @_;

    unless (ref $config_or_path) {
	$config_or_path = readConfig($config_or_path);
    }

    return () unless defined $config_or_path->{dependencies};

    return @{$config_or_path->{dependencies}};
}

sub userPrompt {
    my($msg) = @_;

    return if $auto_yes_to_prompts && $quiet;

    print STDERR "\nDo you want to: $msg\n";
    print STDERR "Return to continue, ctrl-c to abort: ";
    if ($auto_yes_to_prompts) {
        print STDERR "[auto-yes]\n";
    } else {
        $_ = <STDIN>;
        die "You provided 'n' for input, aborting anyway"
            if /^n/io;
    }
}

sub runCommand {
    my(@command) = @_;

    print "Running: ", join(" ", @command), "\n";
    quietRunCommand(@command);
}

sub quietRunCommand {
    my(@command) = @_;

    my $ret = system(@command);

    die "'" . join(" ", @command) . "' failed ($ret)\n" unless $ret == 0;
}

sub aliasChdir {
    my($dir) = @_;

    chdir($dir) or confess "Unable to chdir($dir): $!";
    my $here = getcwd();
    return if defined $Cache::alias_cd{$here};
    print "ACD $here -> $dir\n" if 0;
    $Cache::alias_cd{$here} = $dir;
}

sub aliasGetCwd {
    my $here = getcwd();
    print "AG $here -> $Cache::alias_cd{$here}\n" if 0;
    return $Cache::alias_cd{$here} 
        if defined $Cache::alias_cd{$here};
    return $here;
}

sub readMtnOptions {
    my ($src) = @_;

    $src = rootSrcDir() unless defined $src;
    my $fh = new FileHandle("$src/_MTN/options")
        or die "Can't open $src/_MTN/options for read: $!";
    my %ret;
    while(<$fh>) {
        $ret{branch} = $1 if /^\s*branch \"(.+)\"$/o;
        $ret{database} = $1 if /^\s*database \"(.+)\"$/o;
    }
    close($fh);

    return %ret;
}

sub vcVersion {
    unless (defined $Cache::vc_version) {
	my @output = getCmdOutput("mtn --version");

	die "bad return from mtn --version" unless @output == 1;

	local $_ = $output[0];
	die "can't parse '$output[0]'" unless /^monotone (\d+\.\d+\S*) /o;
	$Cache::vc_version = { 'type' => 'monotone', 'version' => $1 };
    }

    die "Internal" unless defined $Cache::vc_version;
    return $Cache::vc_version;
}

sub vcLogRevision {
    my ($revision) = @_;

    $_ = vcVersion();
    my $vcver = "$_->{type}-$_->{version}";
    if ($vcver =~ /^monotone-0.28\b/o) {
	return getCmdOutput("mtn log -r $revision --last 1");
    } elsif ($vcver =~ /^monotone-0.4\d\b/o) {
	return getCmdOutput("mtn log --from $revision --last 1 --no-graph");
    } else {
	die "Don't know how to get revision log on $vcver";
    }
}

=pod

=head1 BUGS

=over

=item *

cdopt/cddbg only work for sh-style shells.

=item *

code-review gets confused by file renames

=item *

pull should walk the current directory before dependent ones to deal
with new dependencies.

=back

=head1 AUTHOR

Eric Anderson <anderse@hpl.hp.com>

=cut
