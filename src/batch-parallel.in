#!@PERL_BINARY@ -w
# -*- Perl -*-
#
#  (c) Copyright 2004-2005, Hewlett-Packard Development Company, LP
#
#  See the file named COPYING for license details
#
# Script for running batch processing type operations, extended
# by a module that controls how the jobs are selected and executed

# TODO: extend code for lsf submission to support -n minproc,maxproc
# and use -R "span[hosts=1]" to make them all be on the same node
# after verifying that this interacts properly with job arrays.

use strict;
use English;
use Getopt::Long;
use Data::Dumper;
use Carp;
use POSIX;
use Cwd ();
use Pod::Usage;
use Sys::Hostname;
use File::stat;
use Fcntl ':mode';
use DirHandle;
use File::Path;
@PERL_MODULES_INC_UNSHIFT@
BEGIN { unshift(@INC,"@expanded_datadir@/bp_modules"); }
use BatchParallel::common;

$|=1;
my $print_manpage;
my $batch_jobwidth;
my $batch_groupsize;
my $batch_maxgroups;
my $local_parallelism;
my ($lsfexec,$codineexec);
my $no_exec;
my $queue;
my $shuffle = 1;
my $show_rebuild;
my $verbose;
my $batch_workdir;

my $default_baseworkdir = "$ENV{HOME}/.batch-parallel/work";

my @dirs;
while(@ARGV > 0 && $ARGV[@ARGV-1] ne '--') {
    unshift(@dirs,pop @ARGV);
}

if (@ARGV == 0) {
    @ARGV = @dirs;
    @dirs = ();
}

my $ret = GetOptions('man!' => \$print_manpage,
		     'w=i' => \$batch_jobwidth,
		     'q=s' => \$queue,
		     'j=i' => \$local_parallelism,
		     'n!' => \$no_exec,
		     'v!' => \$verbose,
		     'lsfexec=i' => \$lsfexec,
		     'codineexec=i' => \$codineexec,
		     'groupsize=i' => \$batch_groupsize,
		     'maxgroups=i' => \$batch_maxgroups,
		     'shuffle!' => \$shuffle,
		     'show-rebuild!' => \$show_rebuild,
		     'batch-workdir' => \$batch_workdir);

usage("error parsing arguments")
    unless $ret;

usage("missing command line arguments") 
    unless @ARGV >= 1;


if (-d "$ENV{HOME}/.bp_modules") {
    # TODO: remove this 2008-06-01 or later
    warn "You have the obsolete ~/.bp_modules directory. It should be moved to
~/.batch-parallel/modules\n";
    unshift(@INC,"$ENV{HOME}/.bp_modules");
}
unshift(@INC, "$ENV{HOME}/.batch-parallel/modules");

my @bp_module_dirs = ("$ENV{HOME}/.batch-parallel/modules", 
		      "@expanded_datadir@/bp_modules");

if (defined $ENV{BP_MODULES}) {
    unshift(@bp_module_dirs,split(/:/o,$ENV{BP_MODULES}));
    unshift(@INC,split(/:/o,$ENV{BP_MODULES}));
}

pod2usage(-verbose => 2) if $print_manpage;

die "can't specify both groupsize and maxgroups"
    if defined $batch_groupsize && defined $batch_maxgroups;

my $bp_fullpath = shift @ARGV;
my $bp_module_name;

my @bp_args = @ARGV;
if ($bp_fullpath =~ m!^(.*)/([^/]+)$!o) {
    my($path,$module) = ($1,$2);
    unshift(@INC,$path);
    $bp_module_name = $module;
} else {
    $bp_module_name = $bp_fullpath;
}

eval "use BatchParallel::$bp_module_name;";
if ($@) {
    die $@;
} else {
    print "Found module via use BatchParallel::$bp_module_name\n"
	if $verbose;
}

my $modulename = "BatchParallel::$bp_module_name";

if (defined $lsfexec) {
    batch_exec('LSB_JOBINDEX', $lsfexec);
    exit(0);
}

if (defined $codineexec) {
    batch_exec('SGE_TASK_ID', $codineexec);
    exit(0);
}

my $module = new $modulename(@bp_args);

die "new $bp_module_name did not return a reference"
    unless defined $module && ref $module;

if (@dirs == 0) {
    @dirs = $module->default_source_locations();
}

unless (defined $batch_jobwidth || defined $local_parallelism) {
    if (-r "/proc/cpuinfo") {
	open(CPUINFO,"/proc/cpuinfo") || die "Can't read /proc/cpuinfo: $!";
	$local_parallelism = 0;
	while(<CPUINFO>) {
	    ++$local_parallelism if /^processor\s+:/o;
	}
	close(CPUINFO);
	print "Using default parallelism $local_parallelism based on number of cpus in /proc/cpuinfo\n";
    } else {
	$local_parallelism = 1;
	print "Using default parallelism $local_parallelism; no other guess available\n";
    }
}

my ($source_count,@things_to_build) = $module->find_things_to_build(@dirs);

die "internal: source_count = $source_count" 
    unless ref $source_count eq '' && $source_count =~ /^\d+$/o;

if ($source_count == 0) {
    print "Didn't find any sources needing processing under: ", join(", ",@dirs), "\n";
    exit(0);
}
my $rebuild_count = @things_to_build;
my $percent = sprintf("%.2f%%",100*$rebuild_count / $source_count);
print "Found $source_count sources, $rebuild_count ($percent) needing rebuild.\n";

exit(0) if $rebuild_count == 0;
if ($show_rebuild) {
    die "broken with new multi-type support";
    print join("\n",map { $_->[1] } @things_to_build), "\n";
    exit(0);
}

if ($shuffle) {
   $module->shuffle(\@things_to_build);
}

$module->pre_exec_setup();

if (defined $local_parallelism) {
    local_parallel();
} else {
    batch_submit();
}

sub usage {
    my %available_modules;
    foreach my $dir (@bp_module_dirs) {
	next unless -d "$dir/BatchParallel";
	opendir(DIR,"$dir/BatchParallel") || die "can't open dir $dir/Bp: $!";
	while(my $file = readdir(DIR)) {
	    next unless $file =~ s/\.pm$//o;
	    $available_modules{$file} = 1;
	}
    }
    delete $available_modules{'common'};
    my $mods = join(" ",sort keys %available_modules);
    pod2usage( -exitval => 'NOEXIT', -verbose => 0 );
    print "    bp modules: $mods
    looked in: @bp_module_dirs
    you can define \$BP_MODULES to add directories
"; 
   confess @_;
}
    
sub finish_child {
    my ($kidinfo) = @_;

    my $pid = wait;
    die "no children?!" unless defined $pid && $pid > 0;
    die "pid $pid not my child?!" unless defined $kidinfo->{$pid};
    my $thing_info = $kidinfo->{$pid};
    if ($? == 0) {
	$module->rebuild_thing_success($thing_info);
    } else {
	$module->rebuild_thing_fail($thing_info);
    }

    delete $kidinfo->{$pid};
}

sub local_parallel {
    print "* Running locally with $local_parallelism parallelism.\n";
    my $nchildren = 0;
    my %kidinfo;
    foreach my $rebuild (@things_to_build) {
	if ($nchildren >= $local_parallelism) {
	    finish_child(\%kidinfo);
	    --$nchildren;
	}

	if ($no_exec) {
	    $module->rebuild_thing_message($rebuild);
	} else {
	    my $pid = fork;
	    die "fork failed: $!" unless defined $pid && $pid >= 0;
	    if ($pid == 0) {
		$module->rebuild_thing_do($rebuild);
		die "error $module -> rebuild_thing_do returned";
		exit(1);
	    } else {
		$kidinfo{$pid} = $rebuild;
		++$nchildren;
	    }
	}
    }

    while($nchildren > 0) {
	finish_child(\%kidinfo);
	--$nchildren;
    }
}

sub batch_submit {
    if (defined $ENV{SGE_ROOT}) {
	codine_submit();
    } elsif (defined $ENV{LSF_ENVDIR}) {
	lsf_submit();
    } else {
	die "Unable to figure out how to do the batch submission, neither \$SGE_ROOT nor \$LSF_ENVDIR are defined";
    }
}

sub clean_a_workdir {
    my($dir, $older_than) = @_;

    my $dh = new DirHandle $dir
	or die "Can't opendir $dir: $!";
    
    foreach my $file (readdir($dh)) {
	next if $file eq '.' || $file eq '..';

	if ($file =~ /^(joblist)|(log\.\d+)$/o) {
	    my $stat = stat("$dir/$file");
	    die "Can't stat $dir/$file: $!"
		unless defined $stat;
	    return if $stat->mtime >= $older_than;
	}
    }
    if ($no_exec) {
	print "Should auto-clean old workdir $dir\n";
    } else {
	print "Note auto-cleaning old workdir $dir\n";
	$dh->rewind;
	foreach my $file (readdir($dh)) {
	    next if $file eq '.' || $file eq '..';
	    
	    unlink("$dir/$file") or die "Can't unlink $dir/$file: $!";
	}
	rmdir($dir) or die "Can't rmdir $dir: $!";
    }
}

sub cleanup_workdir {
    my $dh = new DirHandle "$default_baseworkdir"
	or return;

    # TODO: make cleaning age configurable, 1 week seems a sane
    # starting default since any log output will push the delay forward.
    # if you change the date, update the documentation.

    my $older_than = time - 7 * 24 * 3600;
    foreach my $file (readdir($dh)) {
	next unless $file =~ /^.+\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}$/o;
	clean_a_workdir("$default_baseworkdir/$file", $older_than);
    }
}

sub write_joblist {
    my $workdir;
    if (defined $batch_workdir) {
	$workdir = $batch_workdir;
    } else {
	my $hostname = hostname();
	my @time = localtime(time);
	my $time = sprintf("%d-%02d-%02dT%02d:%02d:%02d",
			   $time[5]+1900, $time[4]+1, $time[3],
			   $time[2], $time[1], $time[0]);
	$workdir = "$default_baseworkdir/$hostname--$time";
	cleanup_workdir(); # Only clean if we are using the default
    }
    die "$workdir already exists??"
	if -d $workdir;

    my $batch_size = 1;
    if (defined $batch_groupsize) {
	$batch_size = $batch_groupsize;
	$batch_maxgroups = 2*@things_to_build / $batch_size;
	$batch_maxgroups = 2000 unless defined $batch_maxgroups;
	if (scalar @things_to_build / $batch_size > $batch_maxgroups) {
	    print "WARNING, increasing batch size from $batch_size to ";
	    $batch_size = ceil(scalar @things_to_build / $batch_size);
	    print "$batch_size to keep below $batch_maxgroups groups\n";
	}
    } else {
	unless (defined $batch_maxgroups) {
	    $batch_maxgroups = $batch_jobwidth * 5;
	    $batch_maxgroups = 2000 if $batch_maxgroups > 2000;
	}
	if (@things_to_build >= $batch_maxgroups) {
	    $batch_size = ceil((scalar @things_to_build) / $batch_maxgroups);
	}
    }

    unless ($no_exec) {
	mkpath($workdir,0, 0755);

	# TODO: consider compressing this, it can get very long in some cases.
	open(BATCH_LIST,">$workdir/joblist")
	    || die "open($workdir/joblist) failed: $!";
	local $Data::Dumper::Purity = 1;
	my $str = Dumper([$module, \@things_to_build]);
	print BATCH_LIST $str;
	close(BATCH_LIST);
	die "write bad $workdir/joblist" 
	    unless -s "$workdir/joblist" == length $str;
    }
    return ($workdir,$batch_size);
}

sub codine_submit {
    die "queue option not supported" if defined $queue;
    print "Running using Codine with $batch_jobwidth job-width, ";
    my ($workdir, $batch_size) = write_joblist(); 
    print "and batch size $batch_size\n";
    my $njobs = ceil(@things_to_build / $batch_size);

    my $cmd = "qsub -b y -r y -cwd -t 1-$njobs -o $workdir/'log.\$TASK_ID' -j y $0 --codineexec=$batch_size $bp_module_name -- $workdir";
    if ($no_exec) {
	print "should run $cmd\n";
    } else {
	print "$cmd\n";
	my $ret = system($cmd);
	die "submit failed ($ret)\n"
	    unless $ret == 0;
    }
}

sub lsf_submit {
    my ($workdir,$batch_size) = write_joblist();
    print "Running using LSF with $batch_jobwidth job-width, ";
    if (defined $queue) {
	print "queue $queue, ";
	$queue = "-q $queue";
    } else {
	$queue = '';
    }
    print "and batch size $batch_size\n";
    my $njobs = ceil(@things_to_build / $batch_size);
    my $hostname = `hostname`;
    chomp($hostname);
    my $jobname = "batch-parallel:$hostname:$$:$bp_module_name:$hostname:[1-$njobs]%$batch_jobwidth";

    my $cmd = "bsub $queue -J '$jobname' -o $workdir/log.%I $0 --lsfexec=$batch_size $bp_module_name -- $workdir";
    if ($no_exec) {
	# TODO: make this print out what we will rebuild...
	print "should run $cmd\n";
    } else {
	print "$cmd\n";
	my $ret = system($cmd);
	die "submit failed ($ret)\n"
	    unless $ret == 0;
    }
}

sub batch_exec {
    my($envvar, $groupsize) = @_;

    die "wrong number of arguments" unless @dirs == 1;
    my $base_index = $ENV{$envvar};
    die "Don't have \$ENV{$envvar}"
	unless defined $base_index;
    die "invalid \$ENV{$envvar} '$base_index'"
	unless $base_index =~ /^\d+$/o;

    die "Invalid base index 0 from \$ENV{$envvar}" 
	unless $base_index > 0;
    --$base_index;
    open(BPENTS,"$dirs[0]/joblist") || die "can't open $dirs[0] for read: $!";
    my $data;
    {
        local $/;
	no strict;
	my $str = <BPENTS>;
	die "no data in $dirs[0]" unless defined $str && length $str > 0;
	close(BPENTS);
	# TODO: move this into a Safe so that we don't leak all of the
	# $VAR# variables
	my $tmp = eval "$str; \$VAR1;";
	die "error in eval of $dirs[0]/joblist: $@" if $@;
	die "error in eval of $dirs[0]/joblist; wrong type" 
	    unless ref $tmp eq 'ARRAY' && @$tmp == 2;
	($module, $data) = @$tmp; # module is global
	die "error in eval of $dirs[0]/joblist; wrong type for module" 
	    unless ref $module eq $modulename;
	die "error in eval of $dirs[0]/joblist; wrong type for things to build" 
	    unless ref $data eq 'ARRAY'
    }
    my $start_index = $base_index * $groupsize;
    my $end_index = $start_index + $groupsize;
    $end_index = @$data if $end_index > @$data;
    die "internal error" unless $end_index > $start_index;

    @things_to_build = ();
    for(my $i=$start_index;$i<$end_index;++$i) {
	push(@things_to_build,$data->[$i]);
    }

    $local_parallelism = 1;
    local_parallel();
}

__END__

=pod

=head1 NAME

batch-parallel - a program to simplify running batch tasks in parallel 

=head1 SYNOPSIS

 % batch-parallel [-n] [(-w batch-job-width) | (-j local-parallelism)] 
   [-q batch-queue] [--maxgroups=#, default min(batch-job-width*5,2000)]
   [--groupsize=#, rebuilds/lsf-job] 
   [--noshuffle # process jobs exactly in order they were found ]
   [--show-rebuild] [--batch-workdir=path]
   [-- (if bp args use -'s)] <bp-module> [bp-module args...] -- dir/file...

=head1 DESCRIPTION

Batch parallel is a script to run a bunch of tasks in parallel either
on a single local machine, or against an LSF cluster.  The modules are
able to quite flexibly determine the tasks that are going to be
performed, but the traditional form is to perform a make-like
transform on one file to convert it to another form.  For example,
re-compressing a bunch of files, converting dataseries files to text,
running NFS source file conversion.

=head1 OPTIONS

=over 4

=item B<-h | --help>

Get help

=item B<--man>

Print out the manual page

=item B<-j> I<local-parallelism>

Run the jobs on the local node with parallelism as specified.  The
default is to run in this mode with parallelism set to the number of cores.

=item B<-n>

No-execute mode.  Do not actually execute anything just say what we would do.

=item B<-w> I<job-width>

Submit the jobs to run in a batch cluster; auto-guesses LSF vs. Codine/SGE.
The job width is the maximum number of parallel jobs to run at any one time.

=item B<--batch-workdir>=I<path>

For batch jobs, batch-parallel needs to write out the jobs to execute and
log the batch output.  This option specifies the directory path for that
information.  If unspecified, it defaults to ~/.batch-parallel/work, and
directories in there are automatically cleaned out after 1 week.

=item ...

=back

=head1 RECIPIES

These recipies explain how to perform certain tasks

=head2 Find out what modules are currently installed

  % batch-parallel

This will provide the usage options, and will list the bp modules that
are installed in the two standard paths ~/.batch-parallel/modules and
/usr/share/bp_modules, and any paths listed in a colon-separated
$BP_MODULES.

=head2 Get usage information for a particular module
  
  % batch-parallel <module> help

This will provide whatever additional help a module has on it's particular
usage and options.  

=head1 CREATING A BATCH-PARALLEL MODULE

=head2 Overview

To create a batch-parallel module, you will first create a perl module
with the package BatchParallel::I<module name>.  You will need to
place it in an appropriate directory, you can run C<batch-parallel> to
get the list of locations it will use.

You will then define your modules parent class as
BatchParallel::common, and populate your module with various functions
that define how your module processes data.  Since batch-parallel uses
the module as an object, you can override any of the standard
methods.

=head2 Explaining your module

There are two methods that explain what your module does, sub usage,
and sub rebuild_thing_message.  rebuild_thing_message is documented
below.

=head3 sub usage

This function is called to provide a usage overview of of your module.
It should print out all of the additional options your module supports.

=head2 Initializing your module

=head3 sub new

This function is called to create a new BatchParallel object; it
should return a blessed object which has all the appropriate methods
defined.  It should also process any additional options handled by the
module.  You only have to override this message if you take options in
addition to your directory/file arguments.

=head2 Finding things to process

There are two ways to define how your module will find "things" to
process.  First you can define C<sub file_is_source>, and second you
can define C<sub find_things_to_build>.  The former is simpler to use,
and the latter is significantly more general as it could for example
take a trace file, determine segments of a single trace file and
generate jobs that will process the separate segments.

=head3 sub file_is_source($this, $prefix, $full_path, $file_name) 

This function returns true if the file is a source file, and false
otherwise.  The prefix is the user-specified tree under which the
search is occurring.  It may be just a file if the user specified a
particular file.  The full path includes the filename.  Later the
function destination_file will be used to construct the output file
from this source, and destfile_out_of_date to determine if it needs
to be rebuilt.

=head3 sub find_things_to_build($this, @sources)

This function returns an array.  The first element is the number of
source files that were located, and the second is a list of things to
build.  Each thing will be passed to rebuild_thing_*.  The default
find_things_to_build() generates a list of filenames.  If you override
this method, then you also need to override rebuild_thing_do,
rebuild_thing_success, rebuild_thing_fail, rebuild_thing_message.

=head3 sub find_possibles($this, @dirs)

This function is called from find_things_to_build, it searches through
@dirs looking for files that return true from &file_is_source.
It returns an array of [$prefix, $pathname] pairs.

=head3 sub determine_things_to_build($this, \@possibles)

This function is called from find_things_to_build, it should go
through the list of possible things to build and return the list of
ones that need to be rebuild.  The list of possibles consists of 
pairs [$prefix, $pathname] where the prefix is the originally specified
prefix under which this possible entry was found.  

By default this function uses the destination_file and
destfile_out_of_date functions to determine which things to build.  If
the standard rebuild function is to be used, the returned list should
consist of triples of [ $prefix, $fullpath, $destpath ].

=head2 Rebuilding things 

=head3 sub rebuild($this, $prefix, $filepath, $destfile)

This function returns true on a successful build, and false or
die/exit(1) on failure.  This is the function that gets called in
order to actually convert filepath into destfile.  You do not need to
worry about removing destfile in case of failure.  C<batch-parallel>
will actually write to destfile-new, and on a successful rebuild, it
will move it to destfile.  Therefore an unsuccessful build won't cause
problems with destfile_out_of_date.  destfile-new is not removed by
default to make debugging easier.  This function may also want to
print out a message about what it is doing, or call an overridden
rebuild_thing_message.

=head3 sub rebuild_thing_do($this, $thing_info)

This function should exit(0) on success or exit(1) on failure.  It
will be passed a single $thing generated by find_things_to_build.  In
the case where some rebuilds can fail and some can succeeed, the
programmer should verify that find_things_to_build will not
accidentally skip rebuilding things that failed to build.  This
function should probably print some message out about what it is
doing, or call an overridden rebuild_thing_message to give the user
some idea as to what is happening.  This function will be called in
a separate process.

=head3 sub rebuild_thing_success($this, $thing_info) 

This function will handle the case where a rebuild was successful, it
should perform any final processing, for example moving destfile-new
to destfile.  This function will be called in serial.

=head3 sub rebuild_thing_fail($this, $thing_info)

This function will handle the case where a rebuild failed, it should
perform any final processing, for example printing out a message about
the failed build.  If this function exits, other jobs which are
running in parallel will continue in the background.

=head3 sub rebuild_thing_message($this, $thing_info)

This function should print out a message about what would be rebuild.
By default it will only be called when C<batch-parallel> is running in
no-execute mode.

=head2 Utility functions

=head3 sub run($this, @command)

This function will execute @command using system after printing out
the command that is about to be executed.  If the command fails, the
function will not return.  It is therefore useful for writing
replacement rebuild_thing_do functions.  You should set $this->{verbose_level}
before calling this function.  At verbose level 1 or greater, run will
print out the command.

=head3 sub file_older($this, $file, @inputs)

This function will determine if $file is older than any of @inputs.
If $file doesn't exist, it is considered older.

=head1 TODO

Ought to have a function that lets rebuild_thing_fail decide to stop
rebuilding on failure, but not have other processes continue in the
background.

=head1 BUGS

Remarkably poor documentation.

=head1 AUTHOR

Eric Anderson <anderse@hpl.hp.com>

